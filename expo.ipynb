{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e72b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input video\n",
    "video_path = \"videoplayback.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Optical flow params\n",
    "farneback_params = dict(\n",
    "    pyr_scale=0.5,\n",
    "    levels=3,\n",
    "    winsize=15,\n",
    "    iterations=3,\n",
    "    poly_n=5,\n",
    "    poly_sigma=1.2,\n",
    "    flags=0\n",
    ")\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Cannot read video\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Writer for explosion-only output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(\"explosion_detected.avi\", fourcc, 20.0, (prev_frame.shape[1], prev_frame.shape[0]))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Frame difference (for sudden brightness increase = explosion)\n",
    "    diff = cv2.absdiff(gray, prev_gray)\n",
    "    _, thresh = cv2.threshold(diff, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # If large bright change -> possible explosion\n",
    "    explosion_area = np.sum(thresh) / 255\n",
    "    if explosion_area > 5000:  # tune threshold\n",
    "        # Optical Flow to find direction of sparks\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, **farneback_params)\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        \n",
    "        # Draw motion vectors\n",
    "        step = 16\n",
    "        h, w = gray.shape\n",
    "        for y in range(0, h, step):\n",
    "            for x in range(0, w, step):\n",
    "                if mag[y, x] > 2:  # strong motion only\n",
    "                    dx = int(x + flow[y, x, 0])\n",
    "                    dy = int(y + flow[y, x, 1])\n",
    "                    cv2.arrowedLine(frame, (x, y), (dx, dy), (0, 0, 255), 2)\n",
    "\n",
    "        cv2.putText(frame, \"Explosion Detected!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3)\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"Explosion & Flow\", frame)\n",
    "\n",
    "    prev_gray = gray\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72034e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--brightness_threshold BRIGHTNESS_THRESHOLD]\n",
      "                             [--motion_threshold MOTION_THRESHOLD]\n",
      "                             video_path\n",
      "ipykernel_launcher.py: error: the following arguments are required: video_path\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\argparse.py:1932\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1932\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\argparse.py:2181\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_actions:\n\u001b[1;32m-> 2181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(\u001b[38;5;28;01mNone\u001b[39;00m, _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe following arguments are required: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   2182\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(required_actions))\n\u001b[0;32m   2184\u001b[0m \u001b[38;5;66;03m# make sure all required groups had one option present\u001b[39;00m\n",
      "\u001b[1;31mArgumentError\u001b[0m: the following arguments are required: video_path",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[1], line 281\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 281\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 249\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    246\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--motion_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m    247\u001b[0m                    help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMotion magnitude threshold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 249\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(args\u001b[38;5;241m.\u001b[39mvideo_path):\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\argparse.py:1896\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1896\u001b[0m     args, argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\argparse.py:1934\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1933\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 1934\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\argparse.py:2671\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2670\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[1;32m-> 2671\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\argparse.py:2658\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m-> 2658\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2143\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2145\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2149\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1342\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1185\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1190\u001b[0m ):\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1192\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1080\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1081\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1083\u001b[0m )\n\u001b[0;32m   1085\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1086\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1150\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "class ExplosionDetector:\n",
    "    def __init__(self, video_path):\n",
    "        self.video_path = video_path\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n",
    "        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Detection parameters\n",
    "        self.brightness_threshold = 50  # Sudden brightness increase\n",
    "        self.motion_threshold = 30      # Motion magnitude threshold\n",
    "        self.explosion_duration = 10    # Frames to consider as one explosion\n",
    "        \n",
    "        # Storage for analysis\n",
    "        self.explosions = []\n",
    "        self.frame_brightness = []\n",
    "        self.optical_flow_history = deque(maxlen=5)\n",
    "        \n",
    "        # For visualization\n",
    "        self.explosion_count = 0\n",
    "        self.current_explosion_frames = []\n",
    "        \n",
    "    def calculate_brightness(self, frame):\n",
    "        \"\"\"Calculate average brightness of frame\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return np.mean(gray)\n",
    "    \n",
    "    def detect_motion_vectors(self, prev_gray, curr_gray):\n",
    "        \"\"\"Calculate optical flow to detect motion patterns\"\"\"\n",
    "        # Calculate dense optical flow\n",
    "        flow = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, \n",
    "                                      corners=cv2.goodFeaturesToTrack(prev_gray, 100, 0.3, 7),\n",
    "                                      nextPts=None,\n",
    "                                      winSize=(15, 15),\n",
    "                                      maxLevel=2,\n",
    "                                      criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "        \n",
    "        if flow[0] is not None:\n",
    "            good_old = flow[0][flow[1].ravel() == 1]\n",
    "            good_new = flow[2][flow[1].ravel() == 1]\n",
    "            \n",
    "            if len(good_old) > 0 and len(good_new) > 0:\n",
    "                # Calculate motion vectors\n",
    "                motion_vectors = good_new - good_old\n",
    "                return motion_vectors\n",
    "        \n",
    "        return np.array([])\n",
    "    \n",
    "    def detect_radial_motion(self, motion_vectors, center_point):\n",
    "        \"\"\"Detect if motion is radiating outward from center (explosion pattern)\"\"\"\n",
    "        if len(motion_vectors) == 0:\n",
    "            return False, []\n",
    "        \n",
    "        # Calculate angles of motion vectors relative to center\n",
    "        radial_count = 0\n",
    "        radial_vectors = []\n",
    "        \n",
    "        for vector in motion_vectors:\n",
    "            angle = np.arctan2(vector[1], vector[0])\n",
    "            magnitude = np.linalg.norm(vector)\n",
    "            \n",
    "            if magnitude > self.motion_threshold:\n",
    "                radial_vectors.append((angle, magnitude))\n",
    "                radial_count += 1\n",
    "        \n",
    "        # If significant radial motion detected\n",
    "        is_radial = radial_count > len(motion_vectors) * 0.3\n",
    "        return is_radial, radial_vectors\n",
    "    \n",
    "    def detect_explosion_in_frame(self, frame, prev_frame, frame_idx):\n",
    "        \"\"\"Detect explosion characteristics in current frame\"\"\"\n",
    "        current_brightness = self.calculate_brightness(frame)\n",
    "        prev_brightness = self.calculate_brightness(prev_frame) if prev_frame is not None else current_brightness\n",
    "        \n",
    "        brightness_change = current_brightness - prev_brightness\n",
    "        \n",
    "        # Convert to grayscale for motion detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY) if prev_frame is not None else gray\n",
    "        \n",
    "        # Detect motion vectors\n",
    "        motion_vectors = self.detect_motion_vectors(prev_gray, gray)\n",
    "        \n",
    "        # Find potential explosion center (brightest region)\n",
    "        blur = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(blur)\n",
    "        \n",
    "        # Check for radial motion from bright center\n",
    "        is_radial, radial_vectors = self.detect_radial_motion(motion_vectors, max_loc)\n",
    "        \n",
    "        # Explosion detection criteria\n",
    "        is_explosion = (\n",
    "            brightness_change > self.brightness_threshold and  # Sudden brightness increase\n",
    "            is_radial and                                       # Radial motion pattern\n",
    "            len(radial_vectors) > 5                            # Sufficient motion vectors\n",
    "        )\n",
    "        \n",
    "        return is_explosion, {\n",
    "            'brightness_change': brightness_change,\n",
    "            'explosion_center': max_loc,\n",
    "            'radial_vectors': radial_vectors,\n",
    "            'frame_idx': frame_idx\n",
    "        }\n",
    "    \n",
    "    def draw_explosion_analysis(self, frame, explosion_data):\n",
    "        \"\"\"Draw explosion analysis on frame\"\"\"\n",
    "        if not explosion_data:\n",
    "            return frame\n",
    "        \n",
    "        center = explosion_data['explosion_center']\n",
    "        radial_vectors = explosion_data['radial_vectors']\n",
    "        \n",
    "        # Draw explosion center\n",
    "        cv2.circle(frame, center, 20, (0, 0, 255), 3)\n",
    "        cv2.putText(frame, 'EXPLOSION CENTER', (center[0]-50, center[1]-30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        # Draw radial motion vectors\n",
    "        scale_factor = 50\n",
    "        for angle, magnitude in radial_vectors:\n",
    "            end_x = int(center[0] + scale_factor * magnitude * np.cos(angle))\n",
    "            end_y = int(center[1] + scale_factor * magnitude * np.sin(angle))\n",
    "            \n",
    "            cv2.arrowedLine(frame, center, (end_x, end_y), (0, 255, 255), 2, tipLength=0.3)\n",
    "        \n",
    "        # Add explosion counter\n",
    "        cv2.putText(frame, f'Explosions Detected: {self.explosion_count}', \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Highlight explosion with colored border\n",
    "        h, w = frame.shape[:2]\n",
    "        cv2.rectangle(frame, (5, 5), (w-5, h-5), (0, 255, 255), 5)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def process_video(self):\n",
    "        \"\"\"Main processing loop\"\"\"\n",
    "        frame_idx = 0\n",
    "        prev_frame = None\n",
    "        last_explosion_frame = -self.explosion_duration\n",
    "        \n",
    "        print(f\"Processing video: {self.video_path}\")\n",
    "        print(f\"Total frames: {self.total_frames}, FPS: {self.fps}\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Detect explosion\n",
    "            is_explosion, explosion_data = self.detect_explosion_in_frame(frame, prev_frame, frame_idx)\n",
    "            \n",
    "            # Store brightness for analysis\n",
    "            self.frame_brightness.append(self.calculate_brightness(frame))\n",
    "            \n",
    "            if is_explosion and (frame_idx - last_explosion_frame) > self.explosion_duration:\n",
    "                self.explosion_count += 1\n",
    "                last_explosion_frame = frame_idx\n",
    "                self.explosions.append(explosion_data)\n",
    "                print(f\"Explosion #{self.explosion_count} detected at frame {frame_idx} ({frame_idx/self.fps:.2f}s)\")\n",
    "            \n",
    "            # Draw analysis on frame\n",
    "            if is_explosion or (frame_idx - last_explosion_frame) < self.explosion_duration:\n",
    "                frame = self.draw_explosion_analysis(frame, explosion_data if is_explosion else self.explosions[-1] if self.explosions else None)\n",
    "            \n",
    "            # Display frame\n",
    "            frame_resized = cv2.resize(frame, (1280, 720))  # Resize for display\n",
    "            cv2.imshow('Explosion Detection', frame_resized)\n",
    "            \n",
    "            # Control playback\n",
    "            key = cv2.waitKey(int(1000/self.fps)) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord(' '):  # Pause/unpause\n",
    "                cv2.waitKey(0)\n",
    "            \n",
    "            prev_frame = frame.copy()\n",
    "            frame_idx += 1\n",
    "        \n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        self.generate_analysis_report()\n",
    "    \n",
    "    def generate_analysis_report(self):\n",
    "        \"\"\"Generate detailed analysis report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"EXPLOSION ANALYSIS REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Video: {self.video_path}\")\n",
    "        print(f\"Total Explosions Detected: {self.explosion_count}\")\n",
    "        print(f\"Video Duration: {self.total_frames/self.fps:.2f} seconds\")\n",
    "        print(f\"Explosion Rate: {self.explosion_count/(self.total_frames/self.fps):.3f} explosions/second\")\n",
    "        \n",
    "        if self.explosions:\n",
    "            print(\"\\nExplosion Details:\")\n",
    "            for i, explosion in enumerate(self.explosions, 1):\n",
    "                frame_idx = explosion['frame_idx']\n",
    "                timestamp = frame_idx / self.fps\n",
    "                print(f\"  Explosion {i}:\")\n",
    "                print(f\"    Time: {timestamp:.2f}s (Frame {frame_idx})\")\n",
    "                print(f\"    Center: {explosion['explosion_center']}\")\n",
    "                print(f\"    Brightness Change: {explosion['brightness_change']:.2f}\")\n",
    "                print(f\"    Motion Vectors: {len(explosion['radial_vectors'])}\")\n",
    "        \n",
    "        # Plot brightness over time\n",
    "        self.plot_brightness_analysis()\n",
    "    \n",
    "    def plot_brightness_analysis(self):\n",
    "        \"\"\"Plot brightness analysis with explosion markers\"\"\"\n",
    "        if not self.frame_brightness:\n",
    "            return\n",
    "        \n",
    "        time_axis = np.arange(len(self.frame_brightness)) / self.fps\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(time_axis, self.frame_brightness, 'b-', linewidth=1, label='Frame Brightness')\n",
    "        \n",
    "        # Mark explosions\n",
    "        explosion_times = [exp['frame_idx']/self.fps for exp in self.explosions]\n",
    "        explosion_brightness = [self.frame_brightness[exp['frame_idx']] for exp in self.explosions if exp['frame_idx'] < len(self.frame_brightness)]\n",
    "        \n",
    "        if explosion_times:\n",
    "            plt.scatter(explosion_times[:len(explosion_brightness)], explosion_brightness, \n",
    "                       color='red', s=100, marker='*', label='Explosions', zorder=5)\n",
    "        \n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Average Frame Brightness')\n",
    "        plt.title(f'Brightness Analysis - {self.explosion_count} Explosions Detected')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Explosion Detection and Analysis')\n",
    "    parser.add_argument('video_path', help='Path to video file')\n",
    "    parser.add_argument('--brightness_threshold', type=float, default=50, \n",
    "                       help='Brightness change threshold for explosion detection')\n",
    "    parser.add_argument('--motion_threshold', type=float, default=30,\n",
    "                       help='Motion magnitude threshold')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if not os.path.exists(args.video_path):\n",
    "        print(f\"Error: Video file '{args.video_path}' not found!\")\n",
    "        return\n",
    "    \n",
    "    # Create detector instance\n",
    "    detector = ExplosionDetector(args.video_path)\n",
    "    detector.brightness_threshold = args.brightness_threshold\n",
    "    detector.motion_threshold = args.motion_threshold\n",
    "    \n",
    "    # Process video\n",
    "    detector.process_video()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For direct execution without command line args\n",
    "    import sys\n",
    "    if len(sys.argv) == 1:\n",
    "        # Option 1: Hardcode your video path here\n",
    "        video_path = r\"C:\\path\\to\\your\\video.mp4\"  # Replace with your actual path\n",
    "        \n",
    "        # Option 2: Or let user input the path\n",
    "        if not os.path.exists(video_path) or video_path == r\"videoplayback.mp4\":\n",
    "            video_path = input(\"Enter video file path: \")\n",
    "        \n",
    "        if os.path.exists(video_path):\n",
    "            print(f\"Loading video: {video_path}\")\n",
    "            detector = ExplosionDetector(video_path)\n",
    "            detector.process_video()\n",
    "        else:\n",
    "            print(\"File not found!\")\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad9cd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done. Explosions detected: 8\n",
      "ðŸ’¾ Output saved at Explosion_Output.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_explosions():\n",
    "    video_path = \"Fire-Cracker.mp4\"              # ðŸ”¹ Input path fixed here\n",
    "    output_path = \"Explosion_Output.mp4\"         # ðŸ”¹ Output video path\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading video.\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Auto thresholds (relative to scene brightness)\n",
    "    avg_brightness = np.mean(prev_gray)\n",
    "    explosion_threshold = avg_brightness * 200   # motion threshold\n",
    "    min_flow_magnitude = 2.0\n",
    "\n",
    "    explosion_count = 0\n",
    "    cooldown = 0  # avoid double counting\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        diff = cv2.absdiff(prev_gray, gray)\n",
    "        _, thresh = cv2.threshold(diff, 40, 255, cv2.THRESH_BINARY)\n",
    "        motion_area = np.sum(thresh) / 255\n",
    "\n",
    "        if motion_area > explosion_threshold and cooldown == 0:\n",
    "            explosion_count += 1\n",
    "            cooldown = fps // 2  # half-second cooldown\n",
    "            cv2.putText(frame, f\"Explosion #{explosion_count}\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,255), 3)\n",
    "\n",
    "            # Optical flow for spark/fire direction\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None,\n",
    "                                                0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            step = 20\n",
    "            h, w = gray.shape\n",
    "            y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2,-1).astype(int)\n",
    "            fx, fy = flow[y, x].T\n",
    "\n",
    "            for (x1, y1, dx, dy) in zip(x, y, fx, fy):\n",
    "                if dx**2 + dy**2 > min_flow_magnitude**2:\n",
    "                    cv2.arrowedLine(frame, (x1, y1),\n",
    "                                    (int(x1+dx), int(y1+dy)),\n",
    "                                    (0,255,0), 2, tipLength=0.5)\n",
    "\n",
    "        if cooldown > 0:\n",
    "            cooldown -= 1\n",
    "\n",
    "        prev_gray = gray.copy()\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"âœ… Done. Explosions detected: {explosion_count}\")\n",
    "    print(f\"ðŸ’¾ Output saved at {output_path}\")\n",
    "\n",
    "\n",
    "# Run it\n",
    "detect_explosions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e2930",
   "metadata": {},
   "source": [
    "Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd48779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done. Total Explosions Detected: 4\n",
      "ðŸ’¾ Output saved as Explosion_Output-1.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_explosions():\n",
    "    video_path = \"Fire-Cracker.mp4\"              # Input path\n",
    "    output_path = \"Explosion_Output-1.mp4\"         # Output video\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"âŒ Error reading video.\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Auto thresholds (relative to scene brightness)\n",
    "    avg_brightness = np.mean(prev_gray)\n",
    "    explosion_threshold = avg_brightness * 200   # motion threshold\n",
    "    min_flow_magnitude = 2.0\n",
    "\n",
    "    explosion_count = 0\n",
    "    cooldown = 0       # prevents double-counting\n",
    "    show_arrows = False\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        diff = cv2.absdiff(prev_gray, gray)\n",
    "        _, thresh = cv2.threshold(diff, 40, 255, cv2.THRESH_BINARY)\n",
    "        motion_area = np.sum(thresh) / 255\n",
    "\n",
    "        # Detect explosion only when a big spike occurs & cooldown is over\n",
    "        if motion_area > explosion_threshold and cooldown == 0:\n",
    "            explosion_count += 1\n",
    "            cooldown = fps * 2   # 2 seconds cooldown to avoid duplicates\n",
    "            show_arrows = True\n",
    "\n",
    "            cv2.putText(frame, f\"Explosion #{explosion_count}\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,255), 3)\n",
    "\n",
    "        # If explosion is happening (sparks still moving)\n",
    "        if show_arrows:\n",
    "            # Optical flow (motion direction)\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None,\n",
    "                                                0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            step = 20\n",
    "            h, w = gray.shape\n",
    "            y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2,-1).astype(int)\n",
    "            fx, fy = flow[y, x].T\n",
    "\n",
    "            # Draw arrows for sparks\n",
    "            for (x1, y1, dx, dy) in zip(x, y, fx, fy):\n",
    "                if dx**2 + dy**2 > min_flow_magnitude**2:\n",
    "                    cv2.arrowedLine(frame, (x1, y1),\n",
    "                                    (int(x1+dx), int(y1+dy)),\n",
    "                                    (0,255,0), 2, tipLength=0.5)\n",
    "\n",
    "            # Highlight explosion region with circle\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for cnt in contours:\n",
    "                if cv2.contourArea(cnt) > 500:  # ignore noise\n",
    "                    (x_c, y_c), radius = cv2.minEnclosingCircle(cnt)\n",
    "                    center = (int(x_c), int(y_c))\n",
    "                    cv2.circle(frame, center, int(radius), (0,0,255), 3)\n",
    "\n",
    "            # Stop showing arrows if motion dies down\n",
    "            if motion_area < explosion_threshold * 0.2:\n",
    "                show_arrows = False\n",
    "\n",
    "        if cooldown > 0:\n",
    "            cooldown -= 1\n",
    "\n",
    "        # Show total explosions on every frame\n",
    "        cv2.putText(frame, f\"Total Explosions: {explosion_count}\", (30, height - 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,0), 2)\n",
    "\n",
    "        prev_gray = gray.copy()\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"âœ… Done. Total Explosions Detected: {explosion_count}\")\n",
    "    print(f\"ðŸ’¾ Output saved as {output_path}\")\n",
    "\n",
    "\n",
    "# Run it\n",
    "detect_explosions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9fd462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/548] confirmed=0 elapsed=0.6s\n",
      "[100/548] confirmed=12 elapsed=17.5s\n",
      "[150/548] confirmed=15 elapsed=38.7s\n",
      "[200/548] confirmed=22 elapsed=67.1s\n",
      "[250/548] confirmed=25 elapsed=99.9s\n",
      "[300/548] confirmed=38 elapsed=122.8s\n",
      "[350/548] confirmed=47 elapsed=157.4s\n",
      "[400/548] confirmed=47 elapsed=191.9s\n",
      "[450/548] confirmed=47 elapsed=215.1s\n",
      "[500/548] confirmed=48 elapsed=215.8s\n",
      "Finished. Total confirmed explosions: 48\n",
      "Output saved to: Explosion_Output-2.mp4\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Stable Explosion Detector\n",
    "\n",
    "- Input: \"Fire-Cracker.mp4\" (fixed filename - change if needed)\n",
    "- Output: \"Explosion_Output_stable.mp4\"\n",
    "\n",
    "Behavior:\n",
    "- Confirms an explosion only when area + brightness spike + motion magnitude hold for N frames.\n",
    "- Keeps arrows and a highlight circle visible until motion decays for several frames.\n",
    "- Uses sparse optical flow (PyrLK) for arrow directions inside each active bbox.\n",
    "- Designed to be robust to short transient sparks and to generalize to other videos.\n",
    "\n",
    "Tune thresholds near the top if you see false positives/negatives.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import deque\n",
    "import math\n",
    "import time\n",
    "\n",
    "# ---------- PARAMETERS (tweak these if needed) ----------\n",
    "INPUT_VIDEO = \"Fire-Cracker.mp4\"\n",
    "OUTPUT_VIDEO = \"Explosion_Output-2.mp4\"\n",
    "\n",
    "ROLLING_BG_FRAMES = 6         # frames used to compute rolling background brightness\n",
    "BRIGHT_DELTA = 15.0           # local brightness must exceed rolling background by this\n",
    "MIN_AREA_FRAC = 0.002         # min motion area fraction of frame to consider (e.g., 0.002 -> 0.2%)\n",
    "MIN_FLOW_MAG = 1.5            # mean optical-flow magnitude threshold inside bbox for candidate\n",
    "MIN_CONFIRM_FRAMES = 2        # candidate must satisfy criteria for this many consecutive frames to be confirmed\n",
    "DECAY_FRAMES = 10             # after motion drops, keep showing arrows/circle for this many frames\n",
    "IOU_MATCH_THRESH = 0.25       # IoU threshold to match detection to existing event\n",
    "MAX_FEATURES_PER_BOX = 80     # max points to sample inside bbox for PyrLK\n",
    "FEATURE_QUALITY = 0.01\n",
    "FEATURE_MIN_DIST = 6\n",
    "MOTION_DIFF_THRESH = 30       # threshold for absdiff -> binary motion map\n",
    "DOWNSCALE_WIDTH = None        # set to int width to downscale for speed, or None to keep original\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def box_iou(boxA, boxB):\n",
    "    xA,yA,wA,hA = boxA; xB,yB,wB,hB = boxB\n",
    "    xA2,yA2 = xA+wA, yA+hA\n",
    "    xB2,yB2 = xB+wB, yB+hB\n",
    "    xi1 = max(xA, xB); yi1 = max(yA, yB)\n",
    "    xi2 = min(xA2, xB2); yi2 = min(yA2, yB2)\n",
    "    inter_w = max(0, xi2-xi1); inter_h = max(0, yi2-yi1)\n",
    "    inter = inter_w * inter_h\n",
    "    union = wA*hA + wB*hB - inter\n",
    "    return inter/union if union>0 else 0.0\n",
    "\n",
    "def clamp_bbox_to_frame(x,y,w,h,fw,fh):\n",
    "    x = max(0, min(x, fw-1))\n",
    "    y = max(0, min(y, fh-1))\n",
    "    w = max(1, min(w, fw-x))\n",
    "    h = max(1, min(h, fh-y))\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def detect_explosions_stable():\n",
    "    if not os.path.exists(INPUT_VIDEO):\n",
    "        raise FileNotFoundError(f\"Input video not found: {INPUT_VIDEO}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(INPUT_VIDEO)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Cannot open video\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "    orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 0)\n",
    "    orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)\n",
    "\n",
    "    # optional downscale for speed\n",
    "    if DOWNSCALE_WIDTH and orig_w>0:\n",
    "        scale = DOWNSCALE_WIDTH / orig_w\n",
    "        W = DOWNSCALE_WIDTH\n",
    "        H = int(orig_h * scale)\n",
    "    else:\n",
    "        W, H = orig_w, orig_h\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (W, H))\n",
    "    if not out.isOpened():\n",
    "        # fallback to avi\n",
    "        out = cv2.VideoWriter(os.path.splitext(OUTPUT_VIDEO)[0]+\".avi\", cv2.VideoWriter_fourcc(*\"XVID\"), fps, (W,H))\n",
    "\n",
    "    ret, first = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        raise RuntimeError(\"Could not read first frame\")\n",
    "    if (W,H) != (orig_w, orig_h):\n",
    "        first = cv2.resize(first, (W,H))\n",
    "    prev_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    prev_gray = cv2.GaussianBlur(prev_gray, (5,5), 0)\n",
    "\n",
    "    # rolling background brightness (global) - initialize with first frame\n",
    "    bg_brightness_hist = deque([float(np.mean(prev_gray))]*ROLLING_BG_FRAMES, maxlen=ROLLING_BG_FRAMES)\n",
    "\n",
    "    # Events structure\n",
    "    # Each event is a dict:\n",
    "    # {id, bbox, active (bool), frames_confirmed (int), decay (int), last_seen_frame (int)}\n",
    "    events = []\n",
    "    next_event_id = 1\n",
    "    confirmed_count = 0\n",
    "\n",
    "    frame_idx = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # LK params for sparse flow\n",
    "    feature_params = dict(maxCorners=MAX_FEATURES_PER_BOX, qualityLevel=FEATURE_QUALITY,\n",
    "                          minDistance=FEATURE_MIN_DIST, blockSize=7)\n",
    "    lk_params = dict(winSize=(21,21), maxLevel=3,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame_idx += 1\n",
    "        if not ret:\n",
    "            break\n",
    "        if (W,H) != (orig_w, orig_h):\n",
    "            frame = cv2.resize(frame, (W,H))\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "        # motion map via frame diff\n",
    "        diff = cv2.absdiff(gray, prev_gray)\n",
    "        _, motion_map = cv2.threshold(diff, MOTION_DIFF_THRESH, 255, cv2.THRESH_BINARY)\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        motion_map = cv2.morphologyEx(motion_map, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        motion_map = cv2.morphologyEx(motion_map, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "        # contours of motion\n",
    "        contours_info = cv2.findContours(motion_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = contours_info[0] if len(contours_info)==2 else contours_info[1]\n",
    "\n",
    "        # Update rolling bg brightness (exclude current frame then compute local delta against mean of history)\n",
    "        bg_mean = float(np.mean(bg_brightness_hist))\n",
    "\n",
    "        # frame-relative thresholds\n",
    "        frame_area = float(W * H)\n",
    "        min_area_pixels = max(40, int(MIN_AREA_FRAC * frame_area))\n",
    "\n",
    "        # For each motion contour, compute local metrics and try to match / create events\n",
    "        detected_boxes = []\n",
    "        candidate_infos = []  # hold info for each candidate contour\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area < min_area_pixels:\n",
    "                continue\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            x,y,w,h = clamp_bbox_to_frame(x,y,w,h,W,H)\n",
    "            detected_boxes.append((x,y,w,h))\n",
    "\n",
    "            # local brightness\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "            if roi.size == 0:\n",
    "                continue\n",
    "            local_mean = float(np.mean(roi))\n",
    "            bright_delta_local = local_mean - bg_mean\n",
    "\n",
    "            # estimate mean optical flow magnitude inside bbox using sparse LK on prev_gray -> gray\n",
    "            mask = np.zeros_like(prev_gray)\n",
    "            mask[y:y+h, x:x+w] = 255\n",
    "            pts = cv2.goodFeaturesToTrack(prev_gray, mask=mask, **feature_params)\n",
    "            mean_flow_mag = 0.0\n",
    "            if pts is not None and len(pts) > 0:\n",
    "                # calc pyrLK for these points\n",
    "                next_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, pts, None, **lk_params)\n",
    "                good_old = pts[status.flatten()==1].reshape(-1,2)\n",
    "                good_new = next_pts[status.flatten()==1].reshape(-1,2)\n",
    "                if len(good_old) > 0:\n",
    "                    deltas = good_new - good_old\n",
    "                    mags = np.linalg.norm(deltas, axis=1)\n",
    "                    mean_flow_mag = float(np.mean(mags))\n",
    "                else:\n",
    "                    mean_flow_mag = 0.0\n",
    "            else:\n",
    "                mean_flow_mag = 0.0\n",
    "\n",
    "            candidate_infos.append({\n",
    "                \"bbox\": (x,y,w,h),\n",
    "                \"area\": area,\n",
    "                \"local_mean\": local_mean,\n",
    "                \"bright_delta\": bright_delta_local,\n",
    "                \"mean_flow_mag\": mean_flow_mag\n",
    "            })\n",
    "\n",
    "        # Match/update existing events with detected boxes\n",
    "        matched_event_idxs = set()\n",
    "        for info in candidate_infos:\n",
    "            x,y,w,h = info[\"bbox\"]\n",
    "            matched = False\n",
    "            for ei, ev in enumerate(events):\n",
    "                iou = box_iou((x,y,w,h), ev[\"bbox\"])\n",
    "                if iou > IOU_MATCH_THRESH:\n",
    "                    # update event\n",
    "                    ev[\"bbox\"] = (\n",
    "                        min(ev[\"bbox\"][0], x),\n",
    "                        min(ev[\"bbox\"][1], y),\n",
    "                        max(ev[\"bbox\"][0]+ev[\"bbox\"][2], x+w) - min(ev[\"bbox\"][0], x),\n",
    "                        max(ev[\"bbox\"][1]+ev[\"bbox\"][3], y+h) - min(ev[\"bbox\"][1], y)\n",
    "                    )\n",
    "                    ev[\"last_seen_frame\"] = frame_idx\n",
    "                    # reset decay if motion present\n",
    "                    ev[\"decay\"] = 0\n",
    "                    matched = True\n",
    "                    matched_event_idxs.add(ei)\n",
    "                    # If event not yet active (confirming), evaluate confirmation logic below\n",
    "                    break\n",
    "            if not matched:\n",
    "                # new candidate: check multi-criteria (area already > min_area)\n",
    "                cond_bright = info[\"bright_delta\"] >= BRIGHT_DELTA\n",
    "                cond_flow = info[\"mean_flow_mag\"] >= MIN_FLOW_MAG\n",
    "                # Candidate: if brightness spike AND flow strong => start / increment candidate\n",
    "                if cond_bright and cond_flow:\n",
    "                    # create a new temporary event as 'candidate'\n",
    "                    ev = {\n",
    "                        \"id\": next_event_id,\n",
    "                        \"bbox\": info[\"bbox\"],\n",
    "                        \"active\": False,               # becomes True after confirmation frames\n",
    "                        \"frames_confirmed\": 1,\n",
    "                        \"decay\": 0,\n",
    "                        \"last_seen_frame\": frame_idx\n",
    "                    }\n",
    "                    events.append(ev)\n",
    "                    next_event_id += 1\n",
    "                else:\n",
    "                    # Not meeting both criteria: do not create a candidate.\n",
    "                    # This avoids counting small random sparks or reflections.\n",
    "                    pass\n",
    "\n",
    "        # Now update confirmation for candidate events and handle activation / decay\n",
    "        for ev in events:\n",
    "            # compute motion & flow inside current ev bbox if present in this frame\n",
    "            x,y,w,h = ev[\"bbox\"]\n",
    "            x,y,w,h = clamp_bbox_to_frame(int(x),int(y),int(w),int(h),W,H)\n",
    "            roi_motion = motion_map[y:y+h, x:x+w]\n",
    "            motion_pixels = int(np.sum(roi_motion)/255)\n",
    "\n",
    "            # sample points inside bbox to compute flow mag\n",
    "            pts = None\n",
    "            mask = np.zeros_like(prev_gray)\n",
    "            mask[y:y+h, x:x+w] = 255\n",
    "            pts = cv2.goodFeaturesToTrack(prev_gray, mask=mask, **feature_params)\n",
    "            mean_flow_mag = 0.0\n",
    "            if pts is not None and len(pts) > 0:\n",
    "                next_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, pts, None, **lk_params)\n",
    "                good_old = pts[status.flatten()==1].reshape(-1,2)\n",
    "                good_new = next_pts[status.flatten()==1].reshape(-1,2)\n",
    "                if len(good_old)>0:\n",
    "                    deltas = good_new - good_old\n",
    "                    mags = np.linalg.norm(deltas, axis=1)\n",
    "                    mean_flow_mag = float(np.mean(mags))\n",
    "            else:\n",
    "                mean_flow_mag = 0.0\n",
    "\n",
    "            # Decide confirmation: if it was previously created as candidate, increase frames_confirmed when current metrics are still strong\n",
    "            # To avoid re-checking brightness here we approximate by requiring motion_pixels and mean_flow_mag strong\n",
    "            area_ok = (motion_pixels >= max(1, int(0.5 * min_area_pixels)))  # some motion inside bbox\n",
    "            flow_ok = (mean_flow_mag >= MIN_FLOW_MAG * 0.7)\n",
    "            if not ev[\"active\"]:\n",
    "                if area_ok and flow_ok:\n",
    "                    ev[\"frames_confirmed\"] += 1\n",
    "                    if ev[\"frames_confirmed\"] >= MIN_CONFIRM_FRAMES:\n",
    "                        ev[\"active\"] = True\n",
    "                        confirmed_count += 1\n",
    "                        # event becomes active; reset decay\n",
    "                        ev[\"decay\"] = 0\n",
    "                else:\n",
    "                    # decay candidate if not sustained\n",
    "                    ev[\"frames_confirmed\"] = max(0, ev[\"frames_confirmed\"] - 1)\n",
    "            else:\n",
    "                # active event: if motion dies, increase decay; else reset decay\n",
    "                if area_ok or flow_ok:\n",
    "                    ev[\"decay\"] = 0\n",
    "                else:\n",
    "                    ev[\"decay\"] += 1\n",
    "\n",
    "        # Remove old events that decayed fully or not seen for long time\n",
    "        events = [ev for ev in events if ev[\"decay\"] <= DECAY_FRAMES and (frame_idx - ev[\"last_seen_frame\"]) <= (fps * 8)]\n",
    "\n",
    "        # --- DRAWING: for each active event draw circle and arrows (arrows persist while event.decay <= DECAY_FRAMES)\n",
    "        display = frame.copy()\n",
    "        for ev in events:\n",
    "            if not ev[\"active\"]:\n",
    "                continue\n",
    "            x,y,w,h = ev[\"bbox\"]\n",
    "            x,y,w,h = clamp_bbox_to_frame(int(x),int(y),int(w),int(h),W,H)\n",
    "\n",
    "            # Motion mask inside bbox & highlight circle\n",
    "            roi_motion = motion_map[y:y+h, x:x+w]\n",
    "            contours_roi_info = cv2.findContours(roi_motion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours_roi = contours_roi_info[0] if len(contours_roi_info)==2 else contours_roi_info[1]\n",
    "            # If ROI has contours, compute an enclosing circle on combined mask\n",
    "            combined_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            for c in contours_roi:\n",
    "                if cv2.contourArea(c) > 20:\n",
    "                    cv2.drawContours(combined_mask, [c], -1, 255, -1)\n",
    "            if np.count_nonzero(combined_mask) > 0:\n",
    "                ys, xs = np.where(combined_mask == 255)\n",
    "                center_local = (int(np.mean(xs)), int(np.mean(ys)))\n",
    "                # convert to frame coords\n",
    "                center_global = (x + center_local[0], y + center_local[1])\n",
    "                # radius: use max distance to edge of combined mask\n",
    "                radius = max(10, int(0.5 * math.sqrt(w*w + h*h)))\n",
    "                cv2.circle(display, center_global, radius, (0,0,255), 3)\n",
    "            else:\n",
    "                # fallback circle on bbox center\n",
    "                cx, cy = x + w//2, y + h//2\n",
    "                radius = max(10, int(0.5 * math.sqrt(w*w + h*h)))\n",
    "                cv2.circle(display, (cx,cy), radius, (0,0,255), 2)\n",
    "\n",
    "            # arrows: sample features inside bbox and compute pyrLK for direction\n",
    "            mask = np.zeros_like(prev_gray)\n",
    "            mask[y:y+h, x:x+w] = 255\n",
    "            pts = cv2.goodFeaturesToTrack(prev_gray, mask=mask, maxCorners=MAX_FEATURES_PER_BOX,\n",
    "                                          qualityLevel=FEATURE_QUALITY, minDistance=FEATURE_MIN_DIST, blockSize=7)\n",
    "            if pts is not None and len(pts) > 0:\n",
    "                next_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, pts, None, **lk_params)\n",
    "                good_old = pts[status.flatten()==1].reshape(-1,2)\n",
    "                good_new = next_pts[status.flatten()==1].reshape(-1,2)\n",
    "                for (ox, oy), (nxp, nyp) in zip(good_old, good_new):\n",
    "                    ox_i, oy_i = int(ox), int(oy)\n",
    "                    nx_i, ny_i = int(nxp), int(nyp)\n",
    "                    dx, dy = nx_i - ox_i, ny_i - oy_i\n",
    "                    if abs(dx) + abs(dy) > 1:\n",
    "                        cv2.arrowedLine(display, (ox_i, oy_i), (nx_i, ny_i), (0,255,255), 1, tipLength=0.35)\n",
    "\n",
    "        # overlay explosion count live\n",
    "        cv2.putText(display, f\"Total Explosions: {confirmed_count}\", (12, H-18),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,0), 2)\n",
    "\n",
    "        out.write(display)\n",
    "\n",
    "        # update rolling brightness and prev frame\n",
    "        bg_brightness_hist.append(float(np.mean(gray)))\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "        # optional progress log\n",
    "        if frame_idx % 50 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"[{frame_idx}/{total_frames if total_frames>0 else '?'}] confirmed={confirmed_count} elapsed={elapsed:.1f}s\")\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Finished. Total confirmed explosions:\", confirmed_count)\n",
    "    print(\"Output saved to:\", OUTPUT_VIDEO)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detect_explosions_stable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_explosions():\n",
    "    video_path = \"Fire-Cracker.mp4\"       # Input\n",
    "    output_path = \"Explosion_Output-3.mp4\"  # Output\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"âŒ Error reading video.\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    explosion_detected = False\n",
    "    explosion_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        diff = cv2.absdiff(prev_gray, gray)\n",
    "        _, thresh = cv2.threshold(diff, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours of motion regions\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if contours:\n",
    "            largest = max(contours, key=cv2.contourArea)\n",
    "            area = cv2.contourArea(largest)\n",
    "\n",
    "            if area > 5000:  # big enough = explosion\n",
    "                if not explosion_detected:\n",
    "                    explosion_detected = True\n",
    "                    explosion_count += 1\n",
    "                    print(f\"ðŸ’¥ Explosion detected at frame {int(cap.get(cv2.CAP_PROP_POS_FRAMES))}\")\n",
    "\n",
    "                # Draw circle around explosion\n",
    "                (x_c, y_c), radius = cv2.minEnclosingCircle(largest)\n",
    "                center = (int(x_c), int(y_c))\n",
    "                cv2.circle(frame, center, int(radius), (0,0,255), 4)\n",
    "\n",
    "                # Compute optical flow for sparks/fire direction\n",
    "                flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None,\n",
    "                                                    0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                step = 20\n",
    "                h, w = gray.shape\n",
    "                y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2,-1).astype(int)\n",
    "                fx, fy = flow[y, x].T\n",
    "\n",
    "                for (x1, y1, dx, dy) in zip(x, y, fx, fy):\n",
    "                    if dx**2 + dy**2 > 4:  # only strong motion\n",
    "                        cv2.arrowedLine(frame, (x1, y1),\n",
    "                                        (int(x1+dx), int(y1+dy)),\n",
    "                                        (0,255,0), 2, tipLength=0.5)\n",
    "\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "        # Overlay total explosions\n",
    "        cv2.putText(frame, f\"Total Explosions: {explosion_count}\", (30, height - 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,0), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"âœ… Done. Final Explosions Counted: {explosion_count}\")\n",
    "    print(f\"ðŸ’¾ Output saved as {output_path}\")\n",
    "\n",
    "\n",
    "# Run it\n",
    "detect_explosions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e25b390",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m explosion_detected:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (x1, y1, dx, dy) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x, y, fx, fy):\n\u001b[1;32m---> 69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dx\u001b[38;5;241m*\u001b[39mdx \u001b[38;5;241m+\u001b[39m dy\u001b[38;5;241m*\u001b[39mdy \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# only strong motions\u001b[39;00m\n\u001b[0;32m     70\u001b[0m             cv2\u001b[38;5;241m.\u001b[39marrowedLine(frame, (x1, y1), (\u001b[38;5;28mint\u001b[39m(x1\u001b[38;5;241m+\u001b[39mdx), \u001b[38;5;28mint\u001b[39m(y1\u001b[38;5;241m+\u001b[39mdy)),\n\u001b[0;32m     71\u001b[0m                             (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m, tipLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\n\u001b[0;32m     73\u001b[0m prev_gray \u001b[38;5;241m=\u001b[39m gray\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input/output paths\n",
    "input_path = \"Fire-Cracker.mp4\"\n",
    "output_path = \"explosion_detected-4.mp4\"\n",
    "\n",
    "# Video setup\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, int(cap.get(cv2.CAP_PROP_FPS)),\n",
    "                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# Background subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=200, varThreshold=100, detectShadows=False)\n",
    "\n",
    "# For optical flow\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "explosion_detected = False\n",
    "explosion_count = 0\n",
    "frames_since_explosion = 0\n",
    "arrow_persistence = 15  # keep arrows for these many frames after sparks die\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Foreground mask for explosion regions\n",
    "    fgmask = fgbg.apply(gray)\n",
    "    fgmask = cv2.medianBlur(fgmask, 5)\n",
    "    fgmask = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    current_explosion = False\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 600:  # adjust threshold\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            center = (x + w // 2, y + h // 2)\n",
    "            cv2.circle(frame, center, max(w, h) // 2, (0, 0, 255), 2)\n",
    "\n",
    "            current_explosion = True\n",
    "\n",
    "    # Explosion event logic\n",
    "    if current_explosion and not explosion_detected:\n",
    "        explosion_detected = True\n",
    "        explosion_count += 1\n",
    "        frames_since_explosion = 0\n",
    "    elif not current_explosion and explosion_detected:\n",
    "        frames_since_explosion += 1\n",
    "        if frames_since_explosion > arrow_persistence:\n",
    "            explosion_detected = False\n",
    "\n",
    "    # Optical flow arrows (for sparks/fire direction)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None,\n",
    "                                        0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    step = 20\n",
    "    h, w = gray.shape\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "\n",
    "    if explosion_detected:\n",
    "        for (x1, y1, dx, dy) in zip(x, y, fx, fy):\n",
    "            if dx*dx + dy*dy > 1:  # only strong motions\n",
    "                cv2.arrowedLine(frame, (x1, y1), (int(x1+dx), int(y1+dy)),\n",
    "                                (0, 255, 0), 2, tipLength=0.4)\n",
    "\n",
    "    prev_gray = gray\n",
    "\n",
    "    # Label\n",
    "    cv2.putText(frame, f\"Explosions Detected: {explosion_count}\",\n",
    "                (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Processing complete. Output saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d835a92",
   "metadata": {},
   "source": [
    "DEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8da68542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video...\n",
      "Processed 30 frames...\n",
      "Processed 60 frames...\n",
      "Processed 90 frames...\n",
      "Processed 120 frames...\n",
      "Processed 150 frames...\n",
      "Processed 180 frames...\n",
      "Processed 210 frames...\n",
      "Processed 240 frames...\n",
      "Processed 270 frames...\n",
      "Processed 300 frames...\n",
      "Processed 330 frames...\n",
      "Processed 360 frames...\n",
      "Processed 390 frames...\n",
      "Processed 420 frames...\n",
      "Processed 450 frames...\n",
      "Processed 480 frames...\n",
      "Processed 510 frames...\n",
      "Processed 540 frames...\n",
      "Analysis complete. Total explosions detected: 10\n",
      "Processed video saved to: firecracker_explosion_analysis.mp4\n",
      "\n",
      "Done! Open 'firecracker_explosion_analysis.mp4' to see the explosion analysis.\n",
      "Total explosions detected: 10\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "class ExplosionDetector:\n",
    "    def __init__(self):\n",
    "        # Parameters for explosion detection\n",
    "        self.brightness_threshold = 200\n",
    "        self.area_threshold = 50\n",
    "        self.frame_history = 10\n",
    "        self.motion_threshold = 5\n",
    "        \n",
    "        # Store previous frames for comparison\n",
    "        self.prev_frames = deque(maxlen=self.frame_history)\n",
    "        self.prev_gray = None\n",
    "        \n",
    "        # Explosion tracking\n",
    "        self.explosion_count = 0\n",
    "        self.explosion_regions = []\n",
    "        \n",
    "    def detect_explosion(self, frame):\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Store current frame\n",
    "        if self.prev_gray is not None:\n",
    "            self.prev_frames.append(self.prev_gray)\n",
    "        self.prev_gray = gray\n",
    "        \n",
    "        if len(self.prev_frames) < self.frame_history:\n",
    "            return frame, False, None\n",
    "        \n",
    "        # Calculate brightness changes\n",
    "        brightness_changes = []\n",
    "        for prev_frame in self.prev_frames:\n",
    "            diff = cv2.absdiff(gray, prev_frame)\n",
    "            brightness_changes.append(diff)\n",
    "        \n",
    "        if not brightness_changes:\n",
    "            return frame, False, None\n",
    "            \n",
    "        # Average the brightness changes\n",
    "        avg_change = np.mean(brightness_changes, axis=0).astype(np.uint8)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        avg_change = cv2.GaussianBlur(avg_change, (5, 5), 0)\n",
    "        \n",
    "        # Threshold to find bright areas\n",
    "        _, bright_mask = cv2.threshold(avg_change, self.brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Morphological operations to clean up the mask\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        bright_mask = cv2.morphologyEx(bright_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        bright_mask = cv2.morphologyEx(bright_mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours in the bright areas\n",
    "        contours, _ = cv2.findContours(bright_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        explosion_detected = False\n",
    "        explosion_center = None\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > self.area_threshold:\n",
    "                explosion_detected = True\n",
    "                \n",
    "                # Calculate center of explosion\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    explosion_center = (cX, cY)\n",
    "                    \n",
    "                    # Draw contour and center\n",
    "                    cv2.drawContours(frame, [contour], -1, (0, 0, 255), 2)\n",
    "                    cv2.circle(frame, explosion_center, 5, (0, 255, 0), -1)\n",
    "                    \n",
    "                    # Store explosion region\n",
    "                    self.explosion_regions.append({\n",
    "                        'center': explosion_center,\n",
    "                        'contour': contour,\n",
    "                        'frame_count': 0\n",
    "                    })\n",
    "        \n",
    "        return frame, explosion_detected, explosion_center\n",
    "    \n",
    "    def analyze_motion_direction(self, frame, explosion_center):\n",
    "        if explosion_center is None or len(self.prev_frames) < 2:\n",
    "            return frame\n",
    "            \n",
    "        # Calculate optical flow for motion direction\n",
    "        prev_frame = self.prev_frames[-1]\n",
    "        current_frame = self.prev_gray\n",
    "        \n",
    "        # Use Lucas-Kanade method for optical flow\n",
    "        feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "        p0 = cv2.goodFeaturesToTrack(prev_frame, mask=None, **feature_params)\n",
    "        \n",
    "        if p0 is not None:\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(prev_frame, current_frame, p0, None)\n",
    "            \n",
    "            if p1 is not None:\n",
    "                # Select good points\n",
    "                good_new = p1[st == 1]\n",
    "                good_old = p0[st == 1]\n",
    "                \n",
    "                # Draw motion vectors\n",
    "                for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                    a, b = new.ravel()\n",
    "                    c, d = old.ravel()\n",
    "                    \n",
    "                    # Only draw vectors near explosion center\n",
    "                    dist_to_explosion = np.sqrt((a - explosion_center[0])**2 + (b - explosion_center[1])**2)\n",
    "                    if dist_to_explosion < 100:  # Only within 100 pixels of explosion\n",
    "                        motion_vector = (a - c, b - d)\n",
    "                        vector_magnitude = np.sqrt(motion_vector[0]**2 + motion_vector[1]**2)\n",
    "                        \n",
    "                        if vector_magnitude > self.motion_threshold:\n",
    "                            # Draw arrow for direction\n",
    "                            cv2.arrowedLine(frame, (int(c), int(d)), (int(a), int(b)), (255, 0, 0), 2)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def update_explosion_regions(self, frame):\n",
    "        # Update and draw explosion regions\n",
    "        for region in self.explosion_regions:\n",
    "            region['frame_count'] += 1\n",
    "            \n",
    "            # Draw expanding circle to represent ongoing explosion\n",
    "            radius = min(50, region['frame_count'] * 5)\n",
    "            cv2.circle(frame, region['center'], radius, (0, 255, 255), 2)\n",
    "        \n",
    "        # Remove old explosions\n",
    "        self.explosion_regions = [r for r in self.explosion_regions if r['frame_count'] < 10]\n",
    "        \n",
    "        return frame\n",
    "\n",
    "def process_video(video_path, output_path=\"output_video.mp4\"):\n",
    "    # Check if video file exists\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file '{video_path}' not found.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = ExplosionDetector()\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    explosion_detected_in_video = False\n",
    "    \n",
    "    print(\"Processing video...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect explosion\n",
    "        processed_frame, explosion_detected, explosion_center = detector.detect_explosion(frame)\n",
    "        \n",
    "        if explosion_detected:\n",
    "            explosion_detected_in_video = True\n",
    "            detector.explosion_count += 1\n",
    "            \n",
    "            # Analyze motion direction\n",
    "            processed_frame = detector.analyze_motion_direction(processed_frame, explosion_center)\n",
    "            \n",
    "            # Add explosion count text\n",
    "            cv2.putText(processed_frame, f\"Explosion #{detector.explosion_count}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        # Update and draw explosion regions\n",
    "        processed_frame = detector.update_explosion_regions(processed_frame)\n",
    "        \n",
    "        # Display total explosion count\n",
    "        cv2.putText(processed_frame, f\"Total Explosions: {detector.explosion_count}\", (10, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display frame number\n",
    "        cv2.putText(processed_frame, f\"Frame: {frame_count}\", (10, height - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Write to output video\n",
    "        out.write(processed_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:  # Print progress every 30 frames\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "    \n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Analysis complete. Total explosions detected: {detector.explosion_count}\")\n",
    "    print(f\"Processed video saved to: {output_path}\")\n",
    "    \n",
    "    if not explosion_detected_in_video:\n",
    "        print(\"No explosions detected in the video.\")\n",
    "        \n",
    "    return detector.explosion_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process the Fire-Cracker.mp4 video\n",
    "    video_file = \"Fire-Cracker.mp4\"\n",
    "    output_file = \"firecracker_explosion_analysis.mp4\"\n",
    "    \n",
    "    explosion_count = process_video(video_file, output_file)\n",
    "    \n",
    "    print(f\"\\nDone! Open '{output_file}' to see the explosion analysis.\")\n",
    "    print(f\"Total explosions detected: {explosion_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41f0cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video...\n",
      "Processed 30 frames...\n",
      "Processed 60 frames...\n",
      "Processed 90 frames...\n",
      "Processed 120 frames...\n",
      "Processed 150 frames...\n",
      "Processed 180 frames...\n",
      "Processed 210 frames...\n",
      "Processed 240 frames...\n",
      "Processed 270 frames...\n",
      "Processed 300 frames...\n",
      "Processed 330 frames...\n",
      "Processed 360 frames...\n",
      "Processed 390 frames...\n",
      "Processed 420 frames...\n",
      "Processed 450 frames...\n",
      "Processed 480 frames...\n",
      "Processed 510 frames...\n",
      "Processed 540 frames...\n",
      "Analysis complete. Total explosions detected: 2\n",
      "Processed video saved to: improved_explosion_analysis.mp4\n",
      "\n",
      "Done! Open 'improved_explosion_analysis.mp4' to see the explosion analysis.\n",
      "Total explosions detected: 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "class ImprovedExplosionDetector:\n",
    "    def __init__(self):\n",
    "        # Parameters for explosion detection\n",
    "        self.brightness_threshold = 220  # Increased for better detection\n",
    "        self.area_threshold = 100  # Increased to filter out small bright areas\n",
    "        self.frame_history = 5\n",
    "        self.motion_threshold = 3\n",
    "        \n",
    "        # Store previous frames for comparison\n",
    "        self.prev_frames = deque(maxlen=self.frame_history)\n",
    "        self.prev_gray = None\n",
    "        \n",
    "        # Explosion tracking\n",
    "        self.explosion_count = 0\n",
    "        self.explosion_regions = []\n",
    "        self.explosion_cooldown = 0  # Prevents multiple counts for the same explosion\n",
    "        \n",
    "    def detect_explosion(self, frame):\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Store current frame\n",
    "        if self.prev_gray is not None:\n",
    "            self.prev_frames.append(self.prev_gray)\n",
    "        self.prev_gray = gray\n",
    "        \n",
    "        if len(self.prev_frames) < self.frame_history:\n",
    "            return frame, False, None\n",
    "        \n",
    "        # Calculate brightness changes\n",
    "        brightness_changes = []\n",
    "        for prev_frame in self.prev_frames:\n",
    "            diff = cv2.absdiff(gray, prev_frame)\n",
    "            brightness_changes.append(diff)\n",
    "        \n",
    "        if not brightness_changes:\n",
    "            return frame, False, None\n",
    "            \n",
    "        # Average the brightness changes\n",
    "        avg_change = np.mean(brightness_changes, axis=0).astype(np.uint8)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        avg_change = cv2.GaussianBlur(avg_change, (9, 9), 0)\n",
    "        \n",
    "        # Threshold to find bright areas\n",
    "        _, bright_mask = cv2.threshold(avg_change, self.brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Morphological operations to clean up the mask\n",
    "        kernel = np.ones((7, 7), np.uint8)\n",
    "        bright_mask = cv2.morphologyEx(bright_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        bright_mask = cv2.morphologyEx(bright_mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours in the bright areas\n",
    "        contours, _ = cv2.findContours(bright_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        explosion_detected = False\n",
    "        explosion_center = None\n",
    "        largest_contour = None\n",
    "        max_area = 0\n",
    "        \n",
    "        # Find the largest bright area (most likely the explosion)\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                largest_contour = contour\n",
    "        \n",
    "        # Check if the largest area meets our threshold\n",
    "        if largest_contour is not None and max_area > self.area_threshold:\n",
    "            explosion_detected = True\n",
    "            \n",
    "            # Calculate center of explosion\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                explosion_center = (cX, cY)\n",
    "                \n",
    "                # Draw contour and center\n",
    "                cv2.drawContours(frame, [largest_contour], -1, (0, 0, 255), 2)\n",
    "                cv2.circle(frame, explosion_center, 5, (0, 255, 0), -1)\n",
    "                \n",
    "                # Store explosion region (only one per frame)\n",
    "                if self.explosion_cooldown <= 0:\n",
    "                    self.explosion_regions.append({\n",
    "                        'center': explosion_center,\n",
    "                        'contour': largest_contour,\n",
    "                        'frame_count': 0\n",
    "                    })\n",
    "                    self.explosion_cooldown = 15  # Set cooldown to prevent multiple counts\n",
    "        \n",
    "        # Decrease cooldown counter\n",
    "        if self.explosion_cooldown > 0:\n",
    "            self.explosion_cooldown -= 1\n",
    "        \n",
    "        return frame, explosion_detected, explosion_center\n",
    "    \n",
    "    def analyze_motion_direction(self, frame, explosion_center):\n",
    "        if explosion_center is None or len(self.prev_frames) < 2:\n",
    "            return frame\n",
    "            \n",
    "        # Calculate optical flow for motion direction\n",
    "        prev_frame = self.prev_frames[-1]\n",
    "        current_frame = self.prev_gray\n",
    "        \n",
    "        # Create a mask around the explosion area\n",
    "        mask = np.zeros_like(current_frame)\n",
    "        x, y = explosion_center\n",
    "        cv2.circle(mask, (x, y), 100, 255, -1)  # Create a circular mask around explosion\n",
    "        \n",
    "        # Use Lucas-Kanade method for optical flow\n",
    "        feature_params = dict(maxCorners=200, qualityLevel=0.1, minDistance=5, blockSize=7)\n",
    "        p0 = cv2.goodFeaturesToTrack(prev_frame, mask=mask, **feature_params)\n",
    "        \n",
    "        if p0 is not None:\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(prev_frame, current_frame, p0, None)\n",
    "            \n",
    "            if p1 is not None:\n",
    "                # Select good points\n",
    "                good_new = p1[st == 1]\n",
    "                good_old = p0[st == 1]\n",
    "                \n",
    "                # Draw motion vectors\n",
    "                for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                    a, b = new.ravel()\n",
    "                    c, d = old.ravel()\n",
    "                    \n",
    "                    # Calculate motion vector\n",
    "                    motion_vector = (a - c, b - d)\n",
    "                    vector_magnitude = np.sqrt(motion_vector[0]**2 + motion_vector[1]**2)\n",
    "                    \n",
    "                    # Only draw significant movements\n",
    "                    if vector_magnitude > self.motion_threshold:\n",
    "                        # Draw arrow for direction\n",
    "                        cv2.arrowedLine(frame, (int(c), int(d)), (int(a), int(b)), (255, 0, 0), 2, tipLength=0.3)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def update_explosion_regions(self, frame):\n",
    "        # Update and draw only the most recent explosion region\n",
    "        if self.explosion_regions:\n",
    "            region = self.explosion_regions[-1]  # Only keep the most recent explosion\n",
    "            region['frame_count'] += 1\n",
    "            \n",
    "            # Draw expanding circle to represent ongoing explosion\n",
    "            radius = min(80, region['frame_count'] * 4)\n",
    "            cv2.circle(frame, region['center'], radius, (0, 255, 255), 2)\n",
    "            \n",
    "            # Remove if it's been too long\n",
    "            if region['frame_count'] > 20:\n",
    "                self.explosion_regions.pop()\n",
    "        \n",
    "        return frame\n",
    "\n",
    "def process_video(video_path, output_path=\"output_video.mp4\"):\n",
    "    # Check if video file exists\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file '{video_path}' not found.\")\n",
    "        return 0\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = ImprovedExplosionDetector()\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return 0\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    explosion_detected_in_video = False\n",
    "    \n",
    "    print(\"Processing video...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect explosion\n",
    "        processed_frame, explosion_detected, explosion_center = detector.detect_explosion(frame)\n",
    "        \n",
    "        if explosion_detected and detector.explosion_cooldown == 14:  # Count only once per explosion\n",
    "            explosion_detected_in_video = True\n",
    "            detector.explosion_count += 1\n",
    "            \n",
    "            # Analyze motion direction\n",
    "            processed_frame = detector.analyze_motion_direction(processed_frame, explosion_center)\n",
    "            \n",
    "            # Add explosion count text\n",
    "            cv2.putText(processed_frame, f\"Explosion #{detector.explosion_count}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        # Update and draw explosion regions\n",
    "        processed_frame = detector.update_explosion_regions(processed_frame)\n",
    "        \n",
    "        # Display total explosion count\n",
    "        cv2.putText(processed_frame, f\"Total Explosions: {detector.explosion_count}\", (10, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display frame number\n",
    "        cv2.putText(processed_frame, f\"Frame: {frame_count}\", (10, height - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Write to output video\n",
    "        out.write(processed_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:  # Print progress every 30 frames\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "    \n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Analysis complete. Total explosions detected: {detector.explosion_count}\")\n",
    "    print(f\"Processed video saved to: {output_path}\")\n",
    "    \n",
    "    if not explosion_detected_in_video:\n",
    "        print(\"No explosions detected in the video.\")\n",
    "        \n",
    "    return detector.explosion_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process the Fire-Cracker.mp4 video\n",
    "    video_file = \"Fire-Cracker.mp4\"\n",
    "    output_file = \"improved_explosion_analysis.mp4\"\n",
    "    \n",
    "    explosion_count = process_video(video_file, output_file)\n",
    "    \n",
    "    print(f\"\\nDone! Open '{output_file}' to see the explosion analysis.\")\n",
    "    print(f\"Total explosions detected: {explosion_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f4cbb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video...\n",
      "Processed 30 frames...\n",
      "Processed 60 frames...\n",
      "Processed 90 frames...\n",
      "Processed 120 frames...\n",
      "Processed 150 frames...\n",
      "Processed 180 frames...\n",
      "Processed 210 frames...\n",
      "Processed 240 frames...\n",
      "Processed 270 frames...\n",
      "Processed 300 frames...\n",
      "Processed 330 frames...\n",
      "Processed 360 frames...\n",
      "Processed 390 frames...\n",
      "Processed 420 frames...\n",
      "Processed 450 frames...\n",
      "Processed 480 frames...\n",
      "Processed 510 frames...\n",
      "Processed 540 frames...\n",
      "Analysis complete. Total explosions detected: 2\n",
      "Processed video saved to: improved_explosion_analysis-1.mp4\n",
      "\n",
      "Done! Open 'improved_explosion_analysis-1.mp4' to see the explosion analysis.\n",
      "Total explosions detected: 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "class ImprovedExplosionDetector:\n",
    "    def __init__(self):\n",
    "        # Parameters for explosion detection\n",
    "        self.brightness_threshold = 220  # Increased for better detection\n",
    "        self.area_threshold = 100  # Increased to filter out small bright areas\n",
    "        self.frame_history = 5\n",
    "        self.motion_threshold = 3\n",
    "        \n",
    "        # Store previous frames for comparison\n",
    "        self.prev_frames = deque(maxlen=self.frame_history)\n",
    "        self.prev_gray = None\n",
    "        \n",
    "        # Explosion tracking\n",
    "        self.explosion_count = 0\n",
    "        self.explosion_regions = []\n",
    "        self.explosion_cooldown = 0  # Prevents multiple counts for the same explosion\n",
    "        \n",
    "    def detect_explosion(self, frame):\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Store current frame\n",
    "        if self.prev_gray is not None:\n",
    "            self.prev_frames.append(self.prev_gray)\n",
    "        self.prev_gray = gray\n",
    "        \n",
    "        if len(self.prev_frames) < self.frame_history:\n",
    "            return frame, False, None\n",
    "        \n",
    "        # Calculate brightness changes\n",
    "        brightness_changes = []\n",
    "        for prev_frame in self.prev_frames:\n",
    "            diff = cv2.absdiff(gray, prev_frame)\n",
    "            brightness_changes.append(diff)\n",
    "        \n",
    "        if not brightness_changes:\n",
    "            return frame, False, None\n",
    "            \n",
    "        # Average the brightness changes\n",
    "        avg_change = np.mean(brightness_changes, axis=0).astype(np.uint8)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        avg_change = cv2.GaussianBlur(avg_change, (9, 9), 0)\n",
    "        \n",
    "        # Threshold to find bright areas\n",
    "        _, bright_mask = cv2.threshold(avg_change, self.brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Morphological operations to clean up the mask\n",
    "        kernel = np.ones((7, 7), np.uint8)\n",
    "        bright_mask = cv2.morphologyEx(bright_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        bright_mask = cv2.morphologyEx(bright_mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours in the bright areas\n",
    "        contours, _ = cv2.findContours(bright_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        explosion_detected = False\n",
    "        explosion_center = None\n",
    "        largest_contour = None\n",
    "        max_area = 0\n",
    "        \n",
    "        # Find the largest bright area (most likely the explosion)\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                largest_contour = contour\n",
    "        \n",
    "        # Check if the largest area meets our threshold\n",
    "        if largest_contour is not None and max_area > self.area_threshold:\n",
    "            explosion_detected = True\n",
    "            \n",
    "            # Calculate center of explosion\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                explosion_center = (cX, cY)\n",
    "                \n",
    "                # Draw contour and center\n",
    "                cv2.drawContours(frame, [largest_contour], -1, (0, 0, 255), 2)\n",
    "                cv2.circle(frame, explosion_center, 5, (0, 255, 0), -1)\n",
    "                \n",
    "                # Store explosion region (only one per frame)\n",
    "                if self.explosion_cooldown <= 0:\n",
    "                    self.explosion_regions.append({\n",
    "                        'center': explosion_center,\n",
    "                        'contour': largest_contour,\n",
    "                        'frame_count': 0\n",
    "                    })\n",
    "                    self.explosion_cooldown = 15  # Set cooldown to prevent multiple counts\n",
    "        \n",
    "        # Decrease cooldown counter\n",
    "        if self.explosion_cooldown > 0:\n",
    "            self.explosion_cooldown -= 1\n",
    "        \n",
    "        return frame, explosion_detected, explosion_center\n",
    "    \n",
    "    def analyze_motion_direction(self, frame, explosion_center):\n",
    "        if explosion_center is None or len(self.prev_frames) < 2:\n",
    "            return frame\n",
    "            \n",
    "        # Calculate optical flow for motion direction\n",
    "        prev_frame = self.prev_frames[-1]\n",
    "        current_frame = self.prev_gray\n",
    "        \n",
    "        # Create a mask around the explosion area\n",
    "        mask = np.zeros_like(current_frame)\n",
    "        x, y = explosion_center\n",
    "        cv2.circle(mask, (x, y), 100, 255, -1)  # Create a circular mask around explosion\n",
    "        \n",
    "        # Use Lucas-Kanade method for optical flow\n",
    "        feature_params = dict(maxCorners=200, qualityLevel=0.1, minDistance=5, blockSize=7)\n",
    "        p0 = cv2.goodFeaturesToTrack(prev_frame, mask=mask, **feature_params)\n",
    "        \n",
    "        if p0 is not None:\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(prev_frame, current_frame, p0, None)\n",
    "            \n",
    "            if p1 is not None:\n",
    "                # Select good points\n",
    "                good_new = p1[st == 1]\n",
    "                good_old = p0[st == 1]\n",
    "                \n",
    "                # Draw motion vectors\n",
    "                for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                    a, b = new.ravel()\n",
    "                    c, d = old.ravel()\n",
    "                    \n",
    "                    # Calculate motion vector\n",
    "                    motion_vector = (a - c, b - d)\n",
    "                    vector_magnitude = np.sqrt(motion_vector[0]**2 + motion_vector[1]**2)\n",
    "                    \n",
    "                    # Only draw significant movements\n",
    "                    if vector_magnitude > self.motion_threshold:\n",
    "                        # Draw arrow for direction\n",
    "                        cv2.arrowedLine(frame, (int(c), int(d)), (int(a), int(b)), (255, 0, 0), 2, tipLength=0.3)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def update_explosion_regions(self, frame):\n",
    "        # Update and draw only the most recent explosion region\n",
    "        if self.explosion_regions:\n",
    "            region = self.explosion_regions[-1]  # Only keep the most recent explosion\n",
    "            region['frame_count'] += 1\n",
    "            \n",
    "            # Draw expanding circle to represent ongoing explosion\n",
    "            radius = min(80, region['frame_count'] * 4)\n",
    "            cv2.circle(frame, region['center'], radius, (0, 255, 255), 2)\n",
    "            \n",
    "            # Remove if it's been too long\n",
    "            if region['frame_count'] > 20:\n",
    "                self.explosion_regions.pop()\n",
    "        \n",
    "        return frame\n",
    "\n",
    "def process_video(video_path, output_path=\"output_video.mp4\"):\n",
    "    # Check if video file exists\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file '{video_path}' not found.\")\n",
    "        return 0\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = ImprovedExplosionDetector()\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return 0\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    explosion_detected_in_video = False\n",
    "    \n",
    "    print(\"Processing video...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect explosion\n",
    "        processed_frame, explosion_detected, explosion_center = detector.detect_explosion(frame)\n",
    "        \n",
    "        if explosion_detected and detector.explosion_cooldown == 14:  # Count only once per explosion\n",
    "            explosion_detected_in_video = True\n",
    "            detector.explosion_count += 1\n",
    "            \n",
    "            # Analyze motion direction\n",
    "            processed_frame = detector.analyze_motion_direction(processed_frame, explosion_center)\n",
    "            \n",
    "            # Add explosion count text\n",
    "            cv2.putText(processed_frame, f\"Explosion #{detector.explosion_count}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        # Update and draw explosion regions\n",
    "        processed_frame = detector.update_explosion_regions(processed_frame)\n",
    "        \n",
    "        # Display total explosion count\n",
    "        cv2.putText(processed_frame, f\"Total Explosions: {detector.explosion_count}\", (10, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display frame number\n",
    "        cv2.putText(processed_frame, f\"Frame: {frame_count}\", (10, height - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Write to output video\n",
    "        out.write(processed_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:  # Print progress every 30 frames\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "    \n",
    "    # Release everything\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Analysis complete. Total explosions detected: {detector.explosion_count}\")\n",
    "    print(f\"Processed video saved to: {output_path}\")\n",
    "    \n",
    "    if not explosion_detected_in_video:\n",
    "        print(\"No explosions detected in the video.\")\n",
    "        \n",
    "    return detector.explosion_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process the Fire-Cracker.mp4 video\n",
    "    video_file = \"Fire-Cracker.mp4\"\n",
    "    output_file = \"improved_explosion_analysis-1.mp4\"\n",
    "    \n",
    "    explosion_count = process_video(video_file, output_file)\n",
    "    \n",
    "    print(f\"\\nDone! Open '{output_file}' to see the explosion analysis.\")\n",
    "    print(f\"Total explosions detected: {explosion_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80652292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video for explosion detection...\n",
      "Press 'q' to stop processing early if running in a compatible environment.\n",
      "Processed 50 frames...\n",
      "Processed 100 frames...\n",
      "Processed 150 frames...\n",
      "Processed 200 frames...\n",
      "Processed 250 frames...\n",
      "Processed 300 frames...\n",
      "Processed 350 frames...\n",
      "Processed 400 frames...\n",
      "Processed 450 frames...\n",
      "Processed 500 frames...\n",
      "Analysis complete. Total explosions detected: 2\n",
      "Processed video saved to: Explosion_Analysis_Result-1.mp4\n",
      "\n",
      "==================================================\n",
      "EXPLOSION ANALYSIS RESULTS\n",
      "==================================================\n",
      "Input video: Fire-Cracker.mp4\n",
      "Output video: Explosion_Analysis_Result-1.mp4\n",
      "Total explosions detected: 2\n",
      "==================================================\n",
      "\n",
      "INSTRUCTIONS:\n",
      "1. Open 'Explosion_Analysis_Result-1.mp4' to view the analysis results\n",
      "2. Explosions are highlighted with:\n",
      "   - Red contours: Explosion boundaries\n",
      "   - Green dot: Epicenter of explosion\n",
      "   - Blue arrows: Direction of sparks/fire\n",
      "   - Yellow circle: Expanding shockwave\n",
      "3. Explosion count is displayed at the top of the video\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class ExplosionAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Detection parameters\n",
    "        self.brightness_threshold = 220\n",
    "        self.area_threshold = 150\n",
    "        self.motion_threshold = 1.5\n",
    "        \n",
    "        # State variables\n",
    "        self.prev_frame = None\n",
    "        self.prev_gray = None\n",
    "        self.explosion_count = 0\n",
    "        self.explosion_active = False\n",
    "        self.explosion_cooldown = 0\n",
    "        self.explosion_center = None\n",
    "        self.explosion_lifetime = 0\n",
    "        \n",
    "    def detect_explosion(self, frame):\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.prev_gray is None:\n",
    "            self.prev_gray = gray\n",
    "            self.prev_frame = frame.copy()\n",
    "            return frame, False, None\n",
    "        \n",
    "        # Calculate absolute difference between frames\n",
    "        frame_diff = cv2.absdiff(gray, self.prev_gray)\n",
    "        \n",
    "        # Apply threshold to find significant changes\n",
    "        _, thresh = cv2.threshold(frame_diff, self.brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Apply morphological operations to clean up the mask\n",
    "        kernel = np.ones((9, 9), np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        explosion_detected = False\n",
    "        explosion_center = None\n",
    "        max_area = 0\n",
    "        largest_contour = None\n",
    "        \n",
    "        # Find the largest bright area\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                largest_contour = contour\n",
    "        \n",
    "        # Check if the largest area meets our threshold\n",
    "        if largest_contour is not None and max_area > self.area_threshold:\n",
    "            explosion_detected = True\n",
    "            \n",
    "            # Calculate center of explosion\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                explosion_center = (cX, cY)\n",
    "                \n",
    "                # Draw contour and center\n",
    "                cv2.drawContours(frame, [largest_contour], -1, (0, 0, 255), 3)\n",
    "                cv2.circle(frame, explosion_center, 8, (0, 255, 0), -1)\n",
    "        \n",
    "        # Update previous frame\n",
    "        self.prev_gray = gray\n",
    "        self.prev_frame = frame.copy()\n",
    "        \n",
    "        return frame, explosion_detected, explosion_center\n",
    "    \n",
    "    def analyze_explosion_dynamics(self, frame, explosion_center):\n",
    "        if explosion_center is None or self.prev_frame is None:\n",
    "            return frame\n",
    "        \n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(self.prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # Create a grid for motion vectors\n",
    "        h, w = flow.shape[:2]\n",
    "        y, x = explosion_center\n",
    "        \n",
    "        # Define the region around the explosion to analyze\n",
    "        y_start = max(0, y - 100)\n",
    "        y_end = min(h, y + 100)\n",
    "        x_start = max(0, x - 100)\n",
    "        x_end = min(w, x + 100)\n",
    "        \n",
    "        step = 12  # Sample every 12 pixels\n",
    "        \n",
    "        # Draw motion vectors in the explosion region\n",
    "        for i in range(y_start, y_end, step):\n",
    "            for j in range(x_start, x_end, step):\n",
    "                dx, dy = flow[i, j]\n",
    "                magnitude = np.sqrt(dx**2 + dy**2)\n",
    "                \n",
    "                # Only draw significant movements\n",
    "                if magnitude > self.motion_threshold:\n",
    "                    # Draw arrow for direction\n",
    "                    end_point = (int(j + dx*3), int(i + dy*3))  # Scale for visibility\n",
    "                    cv2.arrowedLine(frame, (j, i), end_point, (255, 0, 0), 2, tipLength=0.4)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def update_explosion_state(self, explosion_detected, explosion_center):\n",
    "        # Handle explosion cooldown\n",
    "        if self.explosion_cooldown > 0:\n",
    "            self.explosion_cooldown -= 1\n",
    "        \n",
    "        # Detect new explosion\n",
    "        if explosion_detected and not self.explosion_active and self.explosion_cooldown <= 0:\n",
    "            self.explosion_active = True\n",
    "            self.explosion_count += 1\n",
    "            self.explosion_center = explosion_center\n",
    "            self.explosion_lifetime = 0\n",
    "            self.explosion_cooldown = 25  # Prevent multiple detections\n",
    "        \n",
    "        # Update active explosion\n",
    "        if self.explosion_active:\n",
    "            self.explosion_lifetime += 1\n",
    "            if self.explosion_lifetime > 25:  # Explosion lasts for 25 frames\n",
    "                self.explosion_active = False\n",
    "\n",
    "def process_video(input_path, output_path=\"explosion_analysis_output.mp4\"):\n",
    "    \"\"\"\n",
    "    Process a video to detect explosions, highlight them, show direction arrows, and count explosions.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input video file\n",
    "        output_path (str): Path to save the output video with analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input video '{input_path}' not found.\")\n",
    "        return 0\n",
    "    \n",
    "    # Initialize explosion analyzer\n",
    "    analyzer = ExplosionAnalyzer()\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return 0\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    print(\"Processing video for explosion detection...\")\n",
    "    print(\"Press 'q' to stop processing early if running in a compatible environment.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detect explosion in current frame\n",
    "        processed_frame, explosion_detected, explosion_center = analyzer.detect_explosion(frame)\n",
    "        \n",
    "        # Update explosion state and count\n",
    "        analyzer.update_explosion_state(explosion_detected, explosion_center)\n",
    "        \n",
    "        # If explosion is active, analyze and visualize\n",
    "        if analyzer.explosion_active:\n",
    "            # Analyze explosion dynamics (sparks, fire direction)\n",
    "            processed_frame = analyzer.analyze_explosion_dynamics(processed_frame, analyzer.explosion_center)\n",
    "            \n",
    "            # Draw expanding circle to represent ongoing explosion\n",
    "            radius = min(100, analyzer.explosion_lifetime * 5)\n",
    "            cv2.circle(processed_frame, analyzer.explosion_center, radius, (0, 255, 255), 3)\n",
    "            \n",
    "            # Add explosion count text\n",
    "            cv2.putText(processed_frame, f\"EXPLOSION #{analyzer.explosion_count}\", (20, 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "        \n",
    "        # Display total explosion count\n",
    "        cv2.putText(processed_frame, f\"Total Explosions: {analyzer.explosion_count}\", (20, 90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display frame number\n",
    "        cv2.putText(processed_frame, f\"Frame: {frame_count}\", (20, height - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Write to output video\n",
    "        out.write(processed_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Print progress every 50 frames\n",
    "        if frame_count % 50 == 0:\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Analysis complete. Total explosions detected: {analyzer.explosion_count}\")\n",
    "    print(f\"Processed video saved to: {output_path}\")\n",
    "        \n",
    "    return analyzer.explosion_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    INPUT_VIDEO = \"Fire-Cracker.mp4\"  # Your video file path\n",
    "    OUTPUT_VIDEO = \"Explosion_Analysis_Result-1.mp4\"  # Output video file\n",
    "    \n",
    "    # Process the video\n",
    "    explosion_count = process_video(INPUT_VIDEO, OUTPUT_VIDEO)\n",
    "    \n",
    "    # Results summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXPLOSION ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Input video: {INPUT_VIDEO}\")\n",
    "    print(f\"Output video: {OUTPUT_VIDEO}\")\n",
    "    print(f\"Total explosions detected: {explosion_count}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Instructions for viewing\n",
    "    print(\"\\nINSTRUCTIONS:\")\n",
    "    print(f\"1. Open '{OUTPUT_VIDEO}' to view the analysis results\")\n",
    "    print(\"2. Explosions are highlighted with:\")\n",
    "    print(\"   - Red contours: Explosion boundaries\")\n",
    "    print(\"   - Green dot: Epicenter of explosion\")\n",
    "    print(\"   - Blue arrows: Direction of sparks/fire\")\n",
    "    print(\"   - Yellow circle: Expanding shockwave\")\n",
    "    print(\"3. Explosion count is displayed at the top of the video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fd4524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video for explosion detection...\n",
      "Analyzing explosion dynamics and direction of sparks...\n",
      "Processed 50 frames...\n",
      "Processed 100 frames...\n",
      "Processed 150 frames...\n",
      "Processed 200 frames...\n",
      "Processed 250 frames...\n",
      "Processed 300 frames...\n",
      "Processed 350 frames...\n",
      "Processed 400 frames...\n",
      "Processed 450 frames...\n",
      "Processed 500 frames...\n",
      "Analysis complete. Total explosions detected: 3\n",
      "Processed video saved to: Explosion_Analysis_Result-2.mp4\n",
      "\n",
      "==================================================\n",
      "EXPLOSION ANALYSIS RESULTS\n",
      "==================================================\n",
      "Input video: Fire-Cracker.mp4\n",
      "Output video: Explosion_Analysis_Result-2.mp4\n",
      "Total explosions detected: 3\n",
      "==================================================\n",
      "\n",
      "INSTRUCTIONS:\n",
      "1. Open 'Explosion_Analysis_Result-2.mp4' to view the analysis results\n",
      "2. Explosions are highlighted with:\n",
      "   - Red contours: Explosion boundaries\n",
      "   - Green dot: Epicenter of explosion\n",
      "   - Blue arrows: Direction of sparks/fire\n",
      "   - Yellow circle: Expanding shockwave\n",
      "3. Explosion count is displayed at the top of the video\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class ExplosionAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Detection parameters\n",
    "        self.brightness_threshold = 210\n",
    "        self.area_threshold = 100\n",
    "        self.motion_threshold = 1.0\n",
    "        \n",
    "        # State variables\n",
    "        self.prev_frame = None\n",
    "        self.prev_gray = None\n",
    "        self.prev_bright_mask = None\n",
    "        self.explosion_count = 0\n",
    "        self.explosion_active = False\n",
    "        self.explosion_cooldown = 0\n",
    "        self.explosion_center = None\n",
    "        self.explosion_lifetime = 0\n",
    "        self.explosion_regions = []\n",
    "        \n",
    "    def detect_explosion(self, frame):\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.prev_gray is None:\n",
    "            self.prev_gray = gray\n",
    "            self.prev_frame = frame.copy()\n",
    "            return frame, False, None\n",
    "        \n",
    "        # Calculate absolute difference between frames\n",
    "        frame_diff = cv2.absdiff(gray, self.prev_gray)\n",
    "        \n",
    "        # Apply threshold to find significant changes\n",
    "        _, thresh = cv2.threshold(frame_diff, self.brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Apply morphological operations to clean up the mask\n",
    "        kernel = np.ones((7, 7), np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        explosion_detected = False\n",
    "        explosion_center = None\n",
    "        max_area = 0\n",
    "        largest_contour = None\n",
    "        \n",
    "        # Find the largest bright area\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                largest_contour = contour\n",
    "        \n",
    "        # Check if the largest area meets our threshold\n",
    "        if largest_contour is not None and max_area > self.area_threshold:\n",
    "            explosion_detected = True\n",
    "            \n",
    "            # Calculate center of explosion\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                explosion_center = (cX, cY)\n",
    "                \n",
    "                # Draw contour and center\n",
    "                cv2.drawContours(frame, [largest_contour], -1, (0, 0, 255), 3)\n",
    "                cv2.circle(frame, explosion_center, 8, (0, 255, 0), -1)\n",
    "        \n",
    "        # Update previous frame and bright mask\n",
    "        self.prev_gray = gray\n",
    "        self.prev_frame = frame.copy()\n",
    "        self.prev_bright_mask = thresh\n",
    "        \n",
    "        return frame, explosion_detected, explosion_center\n",
    "    \n",
    "    def analyze_explosion_dynamics(self, frame, explosion_center):\n",
    "        if explosion_center is None or self.prev_frame is None or self.prev_bright_mask is None:\n",
    "            return frame\n",
    "        \n",
    "        # Convert current frame to grayscale\n",
    "        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Create a bright mask for current frame\n",
    "        _, curr_thresh = cv2.threshold(curr_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Find contours in current bright areas\n",
    "        curr_contours, _ = cv2.findContours(curr_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Find contours in previous bright areas\n",
    "        prev_contours, _ = cv2.findContours(self.prev_bright_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # For each bright region in current frame, find direction from explosion center\n",
    "        for contour in curr_contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 20:  # Only consider significant bright areas\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    \n",
    "                    # Calculate direction from explosion center to this bright spot\n",
    "                    dir_x = cX - explosion_center[0]\n",
    "                    dir_y = cY - explosion_center[1]\n",
    "                    \n",
    "                    # Normalize direction vector\n",
    "                    magnitude = np.sqrt(dir_x**2 + dir_y**2)\n",
    "                    if magnitude > 10:  # Only draw arrows for significant movement\n",
    "                        # Scale for visibility\n",
    "                        scale = 30 / magnitude if magnitude > 0 else 0\n",
    "                        end_x = explosion_center[0] + int(dir_x * scale)\n",
    "                        end_y = explosion_center[1] + int(dir_y * scale)\n",
    "                        \n",
    "                        # Draw arrow from explosion center to bright spot\n",
    "                        cv2.arrowedLine(frame, explosion_center, (end_x, end_y), \n",
    "                                       (255, 0, 0), 2, tipLength=0.3)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def update_explosion_state(self, explosion_detected, explosion_center):\n",
    "        # Handle explosion cooldown\n",
    "        if self.explosion_cooldown > 0:\n",
    "            self.explosion_cooldown -= 1\n",
    "        \n",
    "        # Detect new explosion\n",
    "        if explosion_detected and not self.explosion_active and self.explosion_cooldown <= 0:\n",
    "            self.explosion_active = True\n",
    "            self.explosion_count += 1\n",
    "            self.explosion_center = explosion_center\n",
    "            self.explosion_lifetime = 0\n",
    "            self.explosion_cooldown = 25  # Prevent multiple detections\n",
    "            self.explosion_regions.append({\n",
    "                'center': explosion_center,\n",
    "                'lifetime': 0,\n",
    "                'active': True\n",
    "            })\n",
    "        \n",
    "        # Update active explosions\n",
    "        for region in self.explosion_regions:\n",
    "            if region['active']:\n",
    "                region['lifetime'] += 1\n",
    "                if region['lifetime'] > 30:  # Explosion lasts for 30 frames\n",
    "                    region['active'] = False\n",
    "        \n",
    "        # Check if any explosion is still active\n",
    "        self.explosion_active = any(region['active'] for region in self.explosion_regions)\n",
    "\n",
    "def process_video(input_path, output_path=\"explosion_analysis_output.mp4\"):\n",
    "    \"\"\"\n",
    "    Process a video to detect explosions, highlight them, show direction arrows, and count explosions.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input video file\n",
    "        output_path (str): Path to save the output video with analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input video '{input_path}' not found.\")\n",
    "        return 0\n",
    "    \n",
    "    # Initialize explosion analyzer\n",
    "    analyzer = ExplosionAnalyzer()\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return 0\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    print(\"Processing video for explosion detection...\")\n",
    "    print(\"Analyzing explosion dynamics and direction of sparks...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Create a copy for processing\n",
    "        processed_frame = frame.copy()\n",
    "        \n",
    "        # Detect explosion in current frame\n",
    "        processed_frame, explosion_detected, explosion_center = analyzer.detect_explosion(processed_frame)\n",
    "        \n",
    "        # Update explosion state and count\n",
    "        analyzer.update_explosion_state(explosion_detected, explosion_center)\n",
    "        \n",
    "        # If explosion is active, analyze and visualize\n",
    "        if analyzer.explosion_active:\n",
    "            # Analyze explosion dynamics (sparks, fire direction)\n",
    "            processed_frame = analyzer.analyze_explosion_dynamics(processed_frame, analyzer.explosion_center)\n",
    "            \n",
    "            # Draw expanding circles for all active explosions\n",
    "            for region in analyzer.explosion_regions:\n",
    "                if region['active']:\n",
    "                    radius = min(120, region['lifetime'] * 5)\n",
    "                    cv2.circle(processed_frame, region['center'], radius, (0, 255, 255), 2)\n",
    "            \n",
    "            # Add explosion count text\n",
    "            cv2.putText(processed_frame, f\"EXPLOSION #{analyzer.explosion_count}\", (20, 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "        \n",
    "        # Display total explosion count\n",
    "        cv2.putText(processed_frame, f\"Total Explosions: {analyzer.explosion_count}\", (20, 90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display frame number\n",
    "        cv2.putText(processed_frame, f\"Frame: {frame_count}\", (20, height - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Write to output video\n",
    "        out.write(processed_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Print progress every 50 frames\n",
    "        if frame_count % 50 == 0:\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Analysis complete. Total explosions detected: {analyzer.explosion_count}\")\n",
    "    print(f\"Processed video saved to: {output_path}\")\n",
    "        \n",
    "    return analyzer.explosion_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    INPUT_VIDEO = \"Fire-Cracker.mp4\"  # Your video file path\n",
    "    OUTPUT_VIDEO = \"Explosion_Analysis_Result-2.mp4\"  # Output video file\n",
    "    \n",
    "    # Process the video\n",
    "    explosion_count = process_video(INPUT_VIDEO, OUTPUT_VIDEO)\n",
    "    \n",
    "    # Results summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXPLOSION ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Input video: {INPUT_VIDEO}\")\n",
    "    print(f\"Output video: {OUTPUT_VIDEO}\")\n",
    "    print(f\"Total explosions detected: {explosion_count}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Instructions for viewing\n",
    "    print(\"\\nINSTRUCTIONS:\")\n",
    "    print(f\"1. Open '{OUTPUT_VIDEO}' to view the analysis results\")\n",
    "    print(\"2. Explosions are highlighted with:\")\n",
    "    print(\"   - Red contours: Explosion boundaries\")\n",
    "    print(\"   - Green dot: Epicenter of explosion\")\n",
    "    print(\"   - Blue arrows: Direction of sparks/fire\")\n",
    "    print(\"   - Yellow circle: Expanding shockwave\")\n",
    "    print(\"3. Explosion count is displayed at the top of the video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab998d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video for explosion detection...\n",
      "Analyzing explosion dynamics and direction of sparks...\n",
      "Processed 50 frames...\n",
      "Processed 100 frames...\n",
      "Processed 150 frames...\n",
      "Processed 200 frames...\n",
      "Processed 250 frames...\n",
      "Processed 300 frames...\n",
      "Processed 350 frames...\n",
      "Processed 400 frames...\n",
      "Processed 450 frames...\n",
      "Processed 500 frames...\n",
      "Analysis complete. Total explosions detected: 31\n",
      "Processed video saved to: Explosion_Analysis_Result-3.mp4\n",
      "\n",
      "==================================================\n",
      "EXPLOSION ANALYSIS RESULTS\n",
      "==================================================\n",
      "Input video: Fire-Cracker.mp4\n",
      "Output video: Explosion_Analysis_Result-3.mp4\n",
      "Total explosions detected: 31\n",
      "==================================================\n",
      "\n",
      "INSTRUCTIONS:\n",
      "1. Open 'Explosion_Analysis_Result-3.mp4' to view the analysis results\n",
      "2. Explosions are highlighted with:\n",
      "   - Green dot: Epicenter of explosion (persists while fire/sparks exist)\n",
      "   - Blue arrows: Direction of sparks/fire (persists while fire/sparks exist)\n",
      "   - Yellow circle: Expanding shockwave\n",
      "   - Red numbers: Identification number for each explosion\n",
      "3. Explosion count is displayed at the top of the video\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class ExplosionAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Detection parameters\n",
    "        self.brightness_threshold = 180  # Lowered for better detection\n",
    "        self.area_threshold = 50\n",
    "        \n",
    "        # State variables\n",
    "        self.prev_frame = None\n",
    "        self.prev_gray = None\n",
    "        self.explosion_count = 0\n",
    "        self.active_explosions = []  # List to track all active explosions\n",
    "        \n",
    "    def detect_explosions(self, frame):\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.prev_gray is None:\n",
    "            self.prev_gray = gray\n",
    "            self.prev_frame = frame.copy()\n",
    "            return frame, []\n",
    "        \n",
    "        # Calculate absolute difference between frames\n",
    "        frame_diff = cv2.absdiff(gray, self.prev_gray)\n",
    "        \n",
    "        # Apply threshold to find significant changes\n",
    "        _, thresh = cv2.threshold(frame_diff, self.brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Apply morphological operations to clean up the mask\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        explosion_centers = []\n",
    "        \n",
    "        # Process all contours that meet our threshold\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > self.area_threshold:\n",
    "                # Calculate center of bright area\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    explosion_centers.append((cX, cY))\n",
    "        \n",
    "        # Update previous frame\n",
    "        self.prev_gray = gray\n",
    "        self.prev_frame = frame.copy()\n",
    "        \n",
    "        return frame, explosion_centers\n",
    "    \n",
    "    def update_explosion_tracking(self, current_centers):\n",
    "        # Update existing explosions and add new ones\n",
    "        updated_explosions = []\n",
    "        \n",
    "        # First, update existing explosions\n",
    "        for explosion in self.active_explosions:\n",
    "            center, lifetime, arrows = explosion\n",
    "            \n",
    "            # Find if this explosion still exists in current frame\n",
    "            found_match = False\n",
    "            for curr_center in current_centers:\n",
    "                distance = np.sqrt((center[0] - curr_center[0])**2 + (center[1] - curr_center[1])**2)\n",
    "                if distance < 50:  # If close enough, consider it the same explosion\n",
    "                    updated_explosions.append((curr_center, lifetime + 1, arrows))\n",
    "                    found_match = True\n",
    "                    break\n",
    "            \n",
    "            # If no match found but explosion is still recent, keep it with same center\n",
    "            if not found_match and lifetime < 30:\n",
    "                updated_explosions.append((center, lifetime + 1, arrows))\n",
    "        \n",
    "        # Add new explosions\n",
    "        for center in current_centers:\n",
    "            # Check if this is a new explosion (not close to any existing one)\n",
    "            is_new = True\n",
    "            for explosion in updated_explosions:\n",
    "                existing_center, _, _ = explosion\n",
    "                distance = np.sqrt((center[0] - existing_center[0])**2 + (center[1] - existing_center[1])**2)\n",
    "                if distance < 50:\n",
    "                    is_new = False\n",
    "                    break\n",
    "            \n",
    "            if is_new:\n",
    "                updated_explosions.append((center, 1, []))\n",
    "                self.explosion_count += 1\n",
    "        \n",
    "        self.active_explosions = updated_explosions\n",
    "    \n",
    "    def calculate_directions(self, frame):\n",
    "        # Calculate optical flow for direction analysis\n",
    "        if self.prev_frame is None:\n",
    "            return frame\n",
    "        \n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(self.prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # Update arrows for each active explosion\n",
    "        updated_explosions = []\n",
    "        for explosion in self.active_explosions:\n",
    "            center, lifetime, old_arrows = explosion\n",
    "            \n",
    "            # Create new arrows based on optical flow\n",
    "            new_arrows = []\n",
    "            h, w = flow.shape[:2]\n",
    "            x, y = center\n",
    "            \n",
    "            # Define the region around the explosion to analyze\n",
    "            y_start = max(0, y - 80)\n",
    "            y_end = min(h, y + 80)\n",
    "            x_start = max(0, x - 80)\n",
    "            x_end = min(w, x + 80)\n",
    "            \n",
    "            step = 15  # Sample every 15 pixels\n",
    "            \n",
    "            # Create motion vectors in the explosion region\n",
    "            for i in range(y_start, y_end, step):\n",
    "                for j in range(x_start, x_end, step):\n",
    "                    dx, dy = flow[i, j]\n",
    "                    magnitude = np.sqrt(dx**2 + dy**2)\n",
    "                    \n",
    "                    # Only create arrows for significant movements\n",
    "                    if magnitude > 1.0:\n",
    "                        # Store arrow information\n",
    "                        new_arrows.append(((j, i), (int(j + dx*3), int(i + dy*3))))\n",
    "            \n",
    "            updated_explosions.append((center, lifetime, new_arrows))\n",
    "        \n",
    "        self.active_explosions = updated_explosions\n",
    "        return frame\n",
    "    \n",
    "    def draw_explosion_effects(self, frame):\n",
    "        # Draw all effects for active explosions\n",
    "        for explosion in self.active_explosions:\n",
    "            center, lifetime, arrows = explosion\n",
    "            \n",
    "            # Draw explosion center (green dot)\n",
    "            cv2.circle(frame, center, 6, (0, 255, 0), -1)\n",
    "            \n",
    "            # Draw expanding circle (yellow)\n",
    "            radius = min(100, lifetime * 3)\n",
    "            cv2.circle(frame, center, radius, (0, 255, 255), 2)\n",
    "            \n",
    "            # Draw all arrows (blue)\n",
    "            for start, end in arrows:\n",
    "                cv2.arrowedLine(frame, start, end, (255, 0, 0), 2, tipLength=0.3)\n",
    "            \n",
    "            # Draw explosion number near center\n",
    "            explosion_idx = self.active_explosions.index(explosion) + 1\n",
    "            cv2.putText(frame, f\"{explosion_idx}\", \n",
    "                       (center[0] + 10, center[1] - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "def process_video(input_path, output_path=\"explosion_analysis_output.mp4\"):\n",
    "    \"\"\"\n",
    "    Process a video to detect explosions, highlight them, show direction arrows, and count explosions.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input video file\n",
    "        output_path (str): Path to save the output video with analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input video '{input_path}' not found.\")\n",
    "        return 0\n",
    "    \n",
    "    # Initialize explosion analyzer\n",
    "    analyzer = ExplosionAnalyzer()\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return 0\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    print(\"Processing video for explosion detection...\")\n",
    "    print(\"Analyzing explosion dynamics and direction of sparks...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Create a copy for processing\n",
    "        processed_frame = frame.copy()\n",
    "        \n",
    "        # Detect explosions in current frame\n",
    "        processed_frame, explosion_centers = analyzer.detect_explosions(processed_frame)\n",
    "        \n",
    "        # Update explosion tracking\n",
    "        analyzer.update_explosion_tracking(explosion_centers)\n",
    "        \n",
    "        # Calculate directions for active explosions\n",
    "        processed_frame = analyzer.calculate_directions(processed_frame)\n",
    "        \n",
    "        # Draw all explosion effects (dots, circles, arrows)\n",
    "        processed_frame = analyzer.draw_explosion_effects(processed_frame)\n",
    "        \n",
    "        # Display total explosion count\n",
    "        cv2.putText(processed_frame, f\"Total Explosions: {analyzer.explosion_count}\", (20, 40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display active explosion count\n",
    "        cv2.putText(processed_frame, f\"Active Explosions: {len(analyzer.active_explosions)}\", (20, 80), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display frame number\n",
    "        cv2.putText(processed_frame, f\"Frame: {frame_count}\", (20, height - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Write to output video\n",
    "        out.write(processed_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Print progress every 50 frames\n",
    "        if frame_count % 50 == 0:\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Analysis complete. Total explosions detected: {analyzer.explosion_count}\")\n",
    "    print(f\"Processed video saved to: {output_path}\")\n",
    "        \n",
    "    return analyzer.explosion_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    INPUT_VIDEO = \"Fire-Cracker.mp4\"  # Your video file path\n",
    "    OUTPUT_VIDEO = \"Explosion_Analysis_Result-3.mp4\"  # Output video file\n",
    "    \n",
    "    # Process the video\n",
    "    explosion_count = process_video(INPUT_VIDEO, OUTPUT_VIDEO)\n",
    "    \n",
    "    # Results summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXPLOSION ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Input video: {INPUT_VIDEO}\")\n",
    "    print(f\"Output video: {OUTPUT_VIDEO}\")\n",
    "    print(f\"Total explosions detected: {explosion_count}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Instructions for viewing\n",
    "    print(\"\\nINSTRUCTIONS:\")\n",
    "    print(f\"1. Open '{OUTPUT_VIDEO}' to view the analysis results\")\n",
    "    print(\"2. Explosions are highlighted with:\")\n",
    "    print(\"   - Green dot: Epicenter of explosion (persists while fire/sparks exist)\")\n",
    "    print(\"   - Blue arrows: Direction of sparks/fire (persists while fire/sparks exist)\")\n",
    "    print(\"   - Yellow circle: Expanding shockwave\")\n",
    "    print(\"   - Red numbers: Identification number for each explosion\")\n",
    "    print(\"3. Explosion count is displayed at the top of the video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7395f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class AccurateExplosionDetector:\n",
    "    def __init__(self):\n",
    "        # Detection parameters - tuned for firecracker videos\n",
    "        self.brightness_threshold = 200\n",
    "        self.area_threshold = 100\n",
    "        self.min_explosion_duration = 5  # frames\n",
    "        self.max_explosion_duration = 30  # frames\n",
    "        \n",
    "        # State variables\n",
    "        self.prev_frame = None\n",
    "        self.prev_gray = None\n",
    "        self.explosion_count = 0\n",
    "        self.active_explosions = []  # List of active explosions with their properties\n",
    "        \n",
    "    def detect_explosions(self, frame):\n",
    "        # Convert to grayscale and apply slight blur to reduce noise\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        if self.prev_gray is None:\n",
    "            self.prev_gray = gray\n",
    "            self.prev_frame = frame.copy()\n",
    "            return frame, []\n",
    "        \n",
    "        # Calculate absolute difference between frames\n",
    "        frame_diff = cv2.absdiff(gray, self.prev_gray)\n",
    "        \n",
    "        # Apply threshold to find significant changes\n",
    "        _, thresh = cv2.threshold(frame_diff, self.brightness_threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Apply morphological operations to clean up the mask\n",
    "        kernel = np.ones((7, 7), np.uint8)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        explosion_centers = []\n",
    "        \n",
    "        # Process all contours that meet our threshold\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > self.area_threshold:\n",
    "                # Calculate center of bright area\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    \n",
    "                    # Additional check: ensure this is actually a bright area in the current frame\n",
    "                    if gray[cY, cX] > 200:  # Pixel at center should be bright\n",
    "                        explosion_centers.append((cX, cY))\n",
    "        \n",
    "        # Update previous frame\n",
    "        self.prev_gray = gray\n",
    "        self.prev_frame = frame.copy()\n",
    "        \n",
    "        return frame, explosion_centers\n",
    "    \n",
    "    def update_explosion_tracking(self, current_centers):\n",
    "        # First, update existing explosions\n",
    "        updated_explosions = []\n",
    "        \n",
    "        for explosion in self.active_explosions:\n",
    "            center, lifetime, max_brightness = explosion\n",
    "            \n",
    "            # Check if this explosion still exists in current frame\n",
    "            found_match = False\n",
    "            min_distance = float('inf')\n",
    "            closest_center = None\n",
    "            \n",
    "            for curr_center in current_centers:\n",
    "                distance = np.sqrt((center[0] - curr_center[0])**2 + (center[1] - curr_center[1])**2)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_center = curr_center\n",
    "            \n",
    "            # If close enough, consider it the same explosion\n",
    "            if min_distance < 50 and closest_center is not None:\n",
    "                # Update with new center and increment lifetime\n",
    "                updated_explosions.append((closest_center, lifetime + 1, max_brightness))\n",
    "                found_match = True\n",
    "            elif lifetime < self.max_explosion_duration:\n",
    "                # Keep the explosion active even if not detected in this frame\n",
    "                updated_explosions.append((center, lifetime + 1, max_brightness))\n",
    "        \n",
    "        # Add new explosions\n",
    "        for center in current_centers:\n",
    "            # Check if this is a new explosion (not close to any existing one)\n",
    "            is_new = True\n",
    "            for explosion in updated_explosions:\n",
    "                existing_center, _, _ = explosion\n",
    "                distance = np.sqrt((center[0] - existing_center[0])**2 + (center[1] - existing_center[1])**2)\n",
    "                if distance < 50:\n",
    "                    is_new = False\n",
    "                    break\n",
    "            \n",
    "            if is_new:\n",
    "                # Get brightness at center for new explosion\n",
    "                gray = cv2.cvtColor(self.prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "                brightness = gray[center[1], center[0]]\n",
    "                updated_explosions.append((center, 1, brightness))\n",
    "                self.explosion_count += 1\n",
    "                print(f\"New explosion detected at frame {len(self.active_explosions)}\")\n",
    "        \n",
    "        # Remove explosions that have been active too long\n",
    "        self.active_explosions = [exp for exp in updated_explosions if exp[1] <= self.max_explosion_duration]\n",
    "    \n",
    "    def calculate_directions(self, frame):\n",
    "        if self.prev_frame is None:\n",
    "            return frame\n",
    "        \n",
    "        # Convert frames to grayscale\n",
    "        prev_gray = cv2.cvtColor(self.prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # For each active explosion, calculate direction vectors\n",
    "        for i, explosion in enumerate(self.active_explosions):\n",
    "            center, lifetime, max_brightness = explosion\n",
    "            x, y = center\n",
    "            \n",
    "            # Only show arrows for explosions that are still bright\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            if gray[y, x] > 150 and lifetime > 1:  # Only if center is still bright\n",
    "                # Create a grid around the explosion center\n",
    "                h, w = flow.shape[:2]\n",
    "                y_start = max(0, y - 60)\n",
    "                y_end = min(h, y + 60)\n",
    "                x_start = max(0, x - 60)\n",
    "                x_end = min(w, x + 60)\n",
    "                \n",
    "                step = 12  # Sample every 12 pixels\n",
    "                \n",
    "                # Draw direction arrows\n",
    "                for i in range(y_start, y_end, step):\n",
    "                    for j in range(x_start, x_end, step):\n",
    "                        dx, dy = flow[i, j]\n",
    "                        magnitude = np.sqrt(dx**2 + dy**2)\n",
    "                        \n",
    "                        # Only draw arrows for significant movement\n",
    "                        if magnitude > 1.5:\n",
    "                            # Draw arrow from point to direction of movement\n",
    "                            end_point = (int(j + dx*3), int(i + dy*3))\n",
    "                            cv2.arrowedLine(frame, (j, i), end_point, (255, 0, 0), 2, tipLength=0.3)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def draw_explosion_effects(self, frame):\n",
    "        # Draw all effects for active explosions\n",
    "        for i, explosion in enumerate(self.active_explosions):\n",
    "            center, lifetime, max_brightness = explosion\n",
    "            x, y = center\n",
    "            \n",
    "            # Only draw if explosion is still active and bright\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            current_brightness = gray[y, x]\n",
    "            \n",
    "            if lifetime >= self.min_explosion_duration and current_brightness > 100:\n",
    "                # Draw explosion center (green dot)\n",
    "                cv2.circle(frame, center, 6, (0, 255, 0), -1)\n",
    "                \n",
    "                # Draw expanding circle (yellow)\n",
    "                radius = min(80, lifetime * 3)\n",
    "                cv2.circle(frame, center, radius, (0, 255, 255), 2)\n",
    "                \n",
    "                # Draw explosion number near center\n",
    "                cv2.putText(frame, f\"{i+1}\", (x + 10, y - 10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "def process_video(input_path, output_path=\"explosion_analysis_output.mp4\"):\n",
    "    \"\"\"\n",
    "    Process a video to detect explosions, highlight them, show direction arrows, and count explosions.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input video file\n",
    "        output_path (str): Path to save the output video with analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input video '{input_path}' not found.\")\n",
    "        return 0\n",
    "    \n",
    "    # Initialize explosion analyzer\n",
    "    analyzer = AccurateExplosionDetector()\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return 0\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    print(\"Processing video for explosion detection...\")\n",
    "    print(\"Analyzing explosion dynamics and direction of sparks...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Create a copy for processing\n",
    "        processed_frame = frame.copy()\n",
    "        \n",
    "        # Detect explosions in current frame\n",
    "        processed_frame, explosion_centers = analyzer.detect_explosions(processed_frame)\n",
    "        \n",
    "        # Update explosion tracking\n",
    "        analyzer.update_explosion_tracking(explosion_centers)\n",
    "        \n",
    "        # Calculate directions for active explosions\n",
    "        processed_frame = analyzer.calculate_directions(processed_frame)\n",
    "        \n",
    "        # Draw all explosion effects (dots, circles, arrows)\n",
    "        processed_frame = analyzer.draw_explosion_effects(processed_frame)\n",
    "        \n",
    "        # Display total explosion count\n",
    "        cv2.putText(processed_frame, f\"Total Explosions: {analyzer.explosion_count}\", (20, 40), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display active explosion count\n",
    "        active_count = len([exp for exp in analyzer.active_explosions if exp[1] >= analyzer.min_explosion_duration])\n",
    "        cv2.putText(processed_frame, f\"Active Explosions: {active_count}\", (20, 80), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        \n",
    "        # Display frame number\n",
    "        cv2.putText(processed_frame, f\"Frame: {frame_count}\", (20, height - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Write to output video\n",
    "        out.write(processed_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Print progress every 50 frames\n",
    "        if frame_count % 50 == 0:\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Analysis complete. Total explosions detected: {analyzer.explosion_count}\")\n",
    "    print(f\"Processed video saved to: {output_path}\")\n",
    "        \n",
    "    return analyzer.explosion_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    INPUT_VIDEO = \"Fire-Cracker.mp4\"  # Your video file path\n",
    "    OUTPUT_VIDEO = \"Accurate_Explosion_Analysis_Result.mp4\"  # Output video file\n",
    "    \n",
    "    # Process the video\n",
    "    explosion_count = process_video(INPUT_VIDEO, OUTPUT_VIDEO)\n",
    "    \n",
    "    # Results summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXPLOSION ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Input video: {INPUT_VIDEO}\")\n",
    "    print(f\"Output video: {OUTPUT_VIDEO}\")\n",
    "    print(f\"Total explosions detected: {explosion_count}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Instructions for viewing\n",
    "    print(\"\\nINSTRUCTIONS:\")\n",
    "    print(f\"1. Open '{OUTPUT_VIDEO}' to view the analysis results\")\n",
    "    print(\"2. Explosions are highlighted with:\")\n",
    "    print(\"   - Green dot: Epicenter of explosion\")\n",
    "    print(\"   - Blue arrows: Direction of sparks/fire\")\n",
    "    print(\"   - Yellow circle: Expanding shockwave\")\n",
    "    print(\"   - Red numbers: Identification number for each explosion\")\n",
    "    print(\"3. Explosion count is displayed at the top of the video\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
